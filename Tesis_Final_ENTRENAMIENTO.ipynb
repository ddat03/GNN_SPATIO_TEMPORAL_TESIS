{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ade022d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DIEGO\\OneDrive\\Escritorio\\Maestria Ciencia de datos\\Tesis\\Tests\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE: MODELADO GNN - KYLE FIELD\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "from tsl.data import SpatioTemporalDataset, SpatioTemporalDataModule\n",
    "from tsl.data.preprocessing import StandardScaler\n",
    "from tsl.data.datamodule.splitters import TemporalSplitter\n",
    "import pytorch_lightning as pl\n",
    "from tsl.engines import Predictor\n",
    "from tsl.metrics.torch import MaskedMAE, MaskedMAPE, MaskedMSE\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tsl.nn.blocks.encoders import RNN\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv\n",
    "from einops.layers.torch import Rearrange\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import random\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"PIPELINE: MODELADO GNN - KYLE FIELD\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53073f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semilla fijada: 42\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def set_seed(seed=42):\n",
    "    \"\"\"Fijar semilla para reproducibilidad\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    pl.seed_everything(seed, workers=True)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)              \n",
    "np.random.seed(SEED)          \n",
    "torch.manual_seed(SEED)       \n",
    "torch.cuda.manual_seed(SEED)  \n",
    "torch.cuda.manual_seed_all(SEED)  \n",
    "\n",
    "# PyTorch Lightning\n",
    "seed_everything(SEED, workers=True)\n",
    "\n",
    "# Configuración adicional para reproducibilidad\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(f\"Semilla fijada: {SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6931c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Cargar CSVs limpios (escala original)\n",
    "train_df = pd.read_csv('train_estratificado.csv')\n",
    "val_df = pd.read_csv('val_estratificado.csv')\n",
    "test_df = pd.read_csv('test_estratificado.csv')\n",
    "\n",
    "\n",
    "# Convertir fechas\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136af9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aplicar log-transform a variables asimétricas\n",
      "Log-transform aplicado a producción\n",
      "\n",
      " Rangos después de log-transform (train):\n",
      "  Oil range:   [0.00, 2.22]\n",
      "  Gas range:   [0.00, 2.71]\n",
      "  Water range: [0.00, 2.24]\n",
      "\n",
      " Estadísticas por pozo (Gas log):\n",
      "  Well_12: mean=2.51, std=0.44\n",
      "  Well_13: mean=2.45, std=0.51\n",
      "  Well_14: mean=2.47, std=0.12\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. APLICAR LOG-TRANSFORM A VARIABLES ASIMÉTRICAS\n",
    "# ============================================================================\n",
    "print(\"\\nAplicar log-transform a variables asimétricas\")\n",
    "\n",
    "# Variables de producción (altamente asimétricas)\n",
    "production_cols = ['Oil (m3)', 'Gas (m3)', 'Produced Water (m3)']\n",
    "\n",
    "for df in [train_df, val_df, test_df]:\n",
    "    # Asegurar valores no negativos\n",
    "    df[production_cols] = df[production_cols].clip(lower=0)\n",
    "    \n",
    "    # Aplicar log1p (log(1+x) para manejar ceros)\n",
    "    df[production_cols] = np.log1p(df[production_cols])\n",
    "\n",
    "print(\"Log-transform aplicado a producción\")\n",
    "\n",
    "# Verificar rangos después de log\n",
    "print(f\"\\n Rangos después de log-transform (train):\")\n",
    "print(f\"  Oil range:   [{train_df['Oil (m3)'].min():.2f}, {train_df['Oil (m3)'].max():.2f}]\")\n",
    "print(f\"  Gas range:   [{train_df['Gas (m3)'].min():.2f}, {train_df['Gas (m3)'].max():.2f}]\")\n",
    "print(f\"  Water range: [{train_df['Produced Water (m3)'].min():.2f}, {train_df['Produced Water (m3)'].max():.2f}]\")\n",
    "\n",
    "# Verificar distribuciones por pozo\n",
    "print(f\"\\n Estadísticas por pozo (Gas log):\")\n",
    "for well in ['Well_12', 'Well_13', 'Well_14']:\n",
    "    gas_mean = train_df[train_df['Well_ID'] == well]['Gas (m3)'].mean()\n",
    "    gas_std = train_df[train_df['Well_ID'] == well]['Gas (m3)'].std()\n",
    "    print(f\"  {well}: mean={gas_mean:.2f}, std={gas_std:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a48a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Definir features y mapping\n",
      "Features: 8\n",
      "Pozos: 3\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. DEFINIR FEATURES Y WELL MAPPING (3 POZOS)\n",
    "# ============================================================================\n",
    "print(\"\\nDefinir features y mapping\")\n",
    "\n",
    "feature_cols = [\n",
    "    'Hours Online', \n",
    "    'Av. WHT (Deg C)', \n",
    "    'Av. WHP (bar)', \n",
    "    'Av. DHT (Deg C)', \n",
    "    'Av. DHP (bar)', \n",
    "    'Oil (m3)',              \n",
    "    'Gas (m3)',              \n",
    "    'Produced Water (m3)'    \n",
    "]\n",
    "\n",
    "# 3 pozos\n",
    "well_mapping = {\n",
    "    'Well_12': 0, \n",
    "    'Well_13': 1, \n",
    "    'Well_14': 2\n",
    "}\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Pozos: {len(well_mapping)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38482eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# 4. FUNCIÓN PARA CREAR TENSORES\n",
    "# ============================================================================\n",
    "def create_tensor_from_df(df, feature_cols, well_mapping):\n",
    "    \"\"\"\n",
    "    Crea tensor [T, N, F] desde DataFrame\n",
    "    T = timesteps, N = nodos, F = features\n",
    "    \"\"\"\n",
    "    # Ordenar por fecha\n",
    "    df = df.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # Obtener fechas únicas ordenadas\n",
    "    dates = sorted(df['Date'].unique())\n",
    "    n_times = len(dates)\n",
    "    n_nodes = len(well_mapping)\n",
    "    n_features = len(feature_cols)\n",
    "    \n",
    "    # Inicializar tensor con ceros\n",
    "    tensor = torch.zeros((n_times, n_nodes, n_features), dtype=torch.float32)\n",
    "    \n",
    "    print(f\"  Creando tensor: {n_times} timesteps × {n_nodes} nodos × {n_features} features\")\n",
    "    \n",
    "    # Llenar tensor fecha por fecha\n",
    "    for date_idx, date in enumerate(dates):\n",
    "        day_data = df[df['Date'] == date]\n",
    "        \n",
    "        # Para cada pozo en esa fecha\n",
    "        for well_id, well_idx in well_mapping.items():\n",
    "            well_day_data = day_data[day_data['Well_ID'] == well_id]\n",
    "            \n",
    "            if len(well_day_data) > 0:\n",
    "                values = well_day_data[feature_cols].iloc[0].values\n",
    "                tensor[date_idx, well_idx, :] = torch.tensor(values, dtype=torch.float32)\n",
    "    \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c951d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crear tensores para cada conjunto\n",
      "  Creando tensor: 4034 timesteps × 3 nodos × 8 features\n",
      "  Creando tensor: 1444 timesteps × 3 nodos × 8 features\n",
      "  Creando tensor: 1336 timesteps × 3 nodos × 8 features\n",
      "\n",
      "Train tensor: torch.Size([4034, 3, 8])\n",
      "Val tensor:   torch.Size([1444, 3, 8])\n",
      "Test tensor:  torch.Size([1336, 3, 8])\n",
      "  Creando tensor: 4034 timesteps × 3 nodos × 3 features\n",
      "  Creando tensor: 1444 timesteps × 3 nodos × 3 features\n",
      "  Creando tensor: 1336 timesteps × 3 nodos × 3 features\n",
      "\n",
      "Tensores TARGET (3 features):\n",
      "  Train: torch.Size([4034, 3, 3])\n",
      "  Val:   torch.Size([1444, 3, 3])\n",
      "  Test:  torch.Size([1336, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. CREAR TENSORES SEPARADOS\n",
    "# ============================================================================\n",
    "print(\"\\nCrear tensores para cada conjunto\")\n",
    "\n",
    "train_tensor = create_tensor_from_df(train_df, feature_cols, well_mapping)\n",
    "val_tensor = create_tensor_from_df(val_df, feature_cols, well_mapping)\n",
    "test_tensor = create_tensor_from_df(test_df, feature_cols, well_mapping)\n",
    "\n",
    "print(f\"\\nTrain tensor: {train_tensor.shape}\")\n",
    "print(f\"Val tensor:   {val_tensor.shape}\")\n",
    "print(f\"Test tensor:  {test_tensor.shape}\")\n",
    "\n",
    "# Crear tensores TARGET (solo 3 features de producción)\n",
    "target_cols = ['Oil (m3)', 'Gas (m3)', 'Produced Water (m3)']\n",
    "\n",
    "train_target = create_tensor_from_df(train_df, target_cols, well_mapping)\n",
    "val_target = create_tensor_from_df(val_df, target_cols, well_mapping)\n",
    "test_target = create_tensor_from_df(test_df, target_cols, well_mapping)\n",
    "\n",
    "print(f\"\\nTensores TARGET (3 features):\")\n",
    "print(f\"  Train: {train_target.shape}\")\n",
    "print(f\"  Val:   {val_target.shape}\")\n",
    "print(f\"  Test:  {test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454a7fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREAR GRAFO ESPACIAL\n",
      "======================================================================\n",
      "Matriz de adyacencia:\n",
      "[[0.    0.021 0.021]\n",
      " [0.021 0.    1.   ]\n",
      " [0.021 1.    0.   ]]\n",
      "\n",
      "Edge index:  torch.Size([2, 6])\n",
      "Edge weight: torch.Size([6])\n",
      "Número de edges: 6\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6: CREAR GRAFO ESPACIAL\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREAR GRAFO ESPACIAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "coords = {\n",
    "    'Well_12': [1.23349, 56.8859],\n",
    "    'Well_13': [1.22352, 56.9148], \n",
    "    'Well_14': [1.22292, 56.9146]\n",
    "}\n",
    "\n",
    "coords_array = np.array([coords[f'Well_{i}'] for i in [12, 13, 14]])\n",
    "distances = squareform(pdist(coords_array, metric='euclidean'))\n",
    "\n",
    "# Convertir a pesos\n",
    "epsilon = 1e-5\n",
    "adj_matrix = 1 / (distances + epsilon)\n",
    "np.fill_diagonal(adj_matrix, 0)\n",
    "adj_matrix = adj_matrix / adj_matrix.max()\n",
    "\n",
    "print(f\"Matriz de adyacencia:\\n{adj_matrix.round(4)}\")\n",
    "\n",
    "# Crear edge_index y edge_weight\n",
    "src_nodes = []\n",
    "dst_nodes = []\n",
    "weights = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            src_nodes.append(i)\n",
    "            dst_nodes.append(j)\n",
    "            weights.append(adj_matrix[i, j])\n",
    "\n",
    "edge_index = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)\n",
    "edge_weight = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "print(f\"\\nEdge index:  {edge_index.shape}\")\n",
    "print(f\"Edge weight: {edge_weight.shape}\")\n",
    "print(f\"Número de edges: {len(src_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d120fdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREAR SCALERS CON DATOS DE TRAIN\n",
      "======================================================================\n",
      "\n",
      "Scalers INPUT (8 features):\n",
      "  [0] Hours Online             : mean= 16.1953, std= 10.8502\n",
      "  [1] Av. WHT (Deg C)          : mean= 45.1368, std= 31.8013\n",
      "  [2] Av. WHP (bar)            : mean= 42.2300, std= 34.9593\n",
      "  [3] Av. DHT (Deg C)          : mean= 67.0081, std= 43.3415\n",
      "  [4] Av. DHP (bar)            : mean= 83.0250, std= 60.6683\n",
      "  [5] Oil (m3)                 : mean=  1.3311, std=  0.8753\n",
      "  [6] Gas (m3)                 : mean=  1.7619, std=  1.1678\n",
      "  [7] Produced Water (m3)      : mean=  0.4984, std=  0.7464\n",
      "\n",
      "Scalers TARGET (3 features):\n",
      "  [0] Oil (m3)                 : mean=  1.3311, std=  0.8753\n",
      "  [1] Gas (m3)                 : mean=  1.7619, std=  1.1678\n",
      "  [2] Produced Water (m3)      : mean=  0.4984, std=  0.7464\n",
      "\n",
      "8 scalers INPUT creados\n",
      "3 scalers TARGET creados\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# ============================================================\n",
    "# 7: CREAR Y AJUSTAR SCALERS (SOLO CON TRAIN)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREAR SCALERS CON DATOS DE TRAIN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Scalers para INPUT (8 features)\n",
    "print(\"\\nScalers INPUT (8 features):\")\n",
    "x_scalers = []\n",
    "\n",
    "for feat_idx in range(8):\n",
    "    scaler = StandardScaler()\n",
    "    train_feat = train_tensor[:, :, feat_idx].numpy()\n",
    "    train_feat_flat = train_feat.reshape(-1, 1)\n",
    "    scaler.fit(train_feat_flat)\n",
    "    x_scalers.append(scaler)\n",
    "    \n",
    "    feat_name = feature_cols[feat_idx]\n",
    "    print(f\"  [{feat_idx}] {feat_name:25s}: mean={scaler.mean_[0]:8.4f}, std={scaler.scale_[0]:8.4f}\")\n",
    "\n",
    "# Scalers para TARGET (3 features)\n",
    "print(\"\\nScalers TARGET (3 features):\")\n",
    "y_scalers = []\n",
    "\n",
    "for feat_idx in range(3):\n",
    "    scaler = StandardScaler()\n",
    "    train_target_feat = train_target[:, :, feat_idx].numpy()\n",
    "    train_target_flat = train_target_feat.reshape(-1, 1)\n",
    "    scaler.fit(train_target_flat)\n",
    "    y_scalers.append(scaler)\n",
    "    \n",
    "    print(f\"  [{feat_idx}] {target_cols[feat_idx]:25s}: mean={scaler.mean_[0]:8.4f}, std={scaler.scale_[0]:8.4f}\")\n",
    "\n",
    "print(f\"\\n{len(x_scalers)} scalers INPUT creados\")\n",
    "print(f\"{len(y_scalers)} scalers TARGET creados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b89fa6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "NORMALIZAR DATOS\n",
      "======================================================================\n",
      "INPUT normalizado:\n",
      "  Train: torch.Size([4034, 3, 8])\n",
      "  Val:   torch.Size([1444, 3, 8])\n",
      "  Test:  torch.Size([1336, 3, 8])\n",
      "\n",
      "TARGET normalizado:\n",
      "  Train: torch.Size([4034, 3, 3])\n",
      "  Val:   torch.Size([1444, 3, 3])\n",
      "  Test:  torch.Size([1336, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8: NORMALIZAR DATOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"NORMALIZAR DATOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def normalize_tensor(tensor, scalers):\n",
    "    \"\"\"Normaliza tensor [T, N, F] con lista de scalers\"\"\"\n",
    "    tensor_norm = tensor.clone()\n",
    "    T, N, F = tensor.shape\n",
    "    \n",
    "    for feat_idx in range(F):\n",
    "        feat_data = tensor[:, :, feat_idx].numpy()\n",
    "        feat_flat = feat_data.reshape(-1, 1)\n",
    "        feat_norm = scalers[feat_idx].transform(feat_flat)\n",
    "        feat_reshaped = feat_norm.reshape(T, N)\n",
    "        tensor_norm[:, :, feat_idx] = torch.from_numpy(feat_reshaped)\n",
    "    \n",
    "    return tensor_norm\n",
    "\n",
    "# Normalizar INPUT\n",
    "train_tensor_norm = normalize_tensor(train_tensor, x_scalers)\n",
    "val_tensor_norm = normalize_tensor(val_tensor, x_scalers)\n",
    "test_tensor_norm = normalize_tensor(test_tensor, x_scalers)\n",
    "\n",
    "# Normalizar TARGET\n",
    "train_target_norm = normalize_tensor(train_target, y_scalers)\n",
    "val_target_norm = normalize_tensor(val_target, y_scalers)\n",
    "test_target_norm = normalize_tensor(test_target, y_scalers)\n",
    "\n",
    "print(f\"INPUT normalizado:\")\n",
    "print(f\"  Train: {train_tensor_norm.shape}\")\n",
    "print(f\"  Val:   {val_tensor_norm.shape}\")\n",
    "print(f\"  Test:  {test_tensor_norm.shape}\")\n",
    "\n",
    "print(f\"\\nTARGET normalizado:\")\n",
    "print(f\"  Train: {train_target_norm.shape}\")\n",
    "print(f\"  Val:   {val_target_norm.shape}\")\n",
    "print(f\"  Test:  {test_target_norm.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a178f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONCATENAR TENSORES MANTENIENDO ORDEN\n",
      "======================================================================\n",
      "full_input_norm:  torch.Size([6814, 3, 8])\n",
      "full_target_norm: torch.Size([6814, 3, 3])\n",
      "\n",
      "Longitudes de tensores:\n",
      "  Train: 4034 timesteps\n",
      "  Val:   1444 timesteps\n",
      "  Test:  1336 timesteps\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9: CONCATENAR PARA DATASET ÚNICO \n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCATENAR TENSORES MANTENIENDO ORDEN\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# CLAVE: Concatenar DESPUÉS de normalizar, ANTES de crear el dataset\n",
    "full_input_norm = torch.cat([train_tensor_norm, val_tensor_norm, test_tensor_norm], dim=0)\n",
    "full_target_norm = torch.cat([train_target_norm, val_target_norm, test_target_norm], dim=0)\n",
    "\n",
    "print(f\"full_input_norm:  {full_input_norm.shape}\")\n",
    "print(f\"full_target_norm: {full_target_norm.shape}\")\n",
    "\n",
    "# Guardar longitudes para el split\n",
    "train_length = len(train_tensor_norm)\n",
    "val_length = len(val_tensor_norm)\n",
    "test_length = len(test_tensor_norm)\n",
    "\n",
    "print(f\"\\nLongitudes de tensores:\")\n",
    "print(f\"  Train: {train_length} timesteps\")\n",
    "print(f\"  Val:   {val_length} timesteps\")\n",
    "print(f\"  Test:  {test_length} timesteps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7473fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREAR UN ÚNICO SPATIOTEMPORALDATASET\n",
      "======================================================================\n",
      "Dataset creado: 6794 samples\n",
      "\n",
      "Dataset esperado:\n",
      "  Total timesteps: 6814\n",
      "  Total samples: 6794\n",
      "  Window: 14, Horizon: 7, Stride: 1\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 10: CREAR UN ÚNICO DATASET\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREAR UN ÚNICO SPATIOTEMPORALDATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "window = 14\n",
    "horizon = 7\n",
    "stride = 1\n",
    "\n",
    "\n",
    "torch_dataset_norm = SpatioTemporalDataset(\n",
    "    target=full_target_norm.numpy(),\n",
    "    covariates={'x': full_input_norm.numpy()},\n",
    "    connectivity=(edge_index, edge_weight),\n",
    "    horizon=horizon,\n",
    "    window=window,\n",
    "    stride=stride\n",
    ")\n",
    "\n",
    "print(f\"Dataset creado: {len(torch_dataset_norm)} samples\")\n",
    "\n",
    "\n",
    "# Calcular tamaños esperados\n",
    "total_length = train_length + val_length + test_length\n",
    "n_total_samples = total_length - window - horizon + 1\n",
    "\n",
    "print(f\"\\nDataset esperado:\")\n",
    "print(f\"  Total timesteps: {total_length}\")\n",
    "print(f\"  Total samples: {n_total_samples}\")\n",
    "print(f\"  Window: {window}, Horizon: {horizon}, Stride: {stride}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccd74802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CALCULAR ÍNDICES DE SPLIT\n",
      "======================================================================\n",
      "\n",
      "Samples por segmento:\n",
      "  Train: 4014 samples (timesteps 0-4033)\n",
      "  Val:   1424 samples (timesteps 4034-5477)\n",
      "  Test:  1316 samples (timesteps 5478-6813)\n",
      "\n",
      "Índices de split:\n",
      "  Train: 0 → 4013 (4014 samples)\n",
      "  Val:   4014 → 5437 (1424 samples)\n",
      "  Test:  5438 → 6753 (1316 samples)\n",
      "  Total: 6754 samples\n",
      "\n",
      "Verificación de índices: CORRECTA\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 11: CALCULAR ÍNDICES DE SPLIT CORRECTOS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CALCULAR ÍNDICES DE SPLIT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calcular cuántos samples genera cada segmento\n",
    "n_train_samples = train_length - window - horizon + 1\n",
    "n_val_samples = val_length - window - horizon + 1\n",
    "n_test_samples = test_length - window - horizon + 1\n",
    "\n",
    "print(f\"\\nSamples por segmento:\")\n",
    "print(f\"  Train: {n_train_samples} samples (timesteps 0-{train_length-1})\")\n",
    "print(f\"  Val:   {n_val_samples} samples (timesteps {train_length}-{train_length+val_length-1})\")\n",
    "print(f\"  Test:  {n_test_samples} samples (timesteps {train_length+val_length}-{total_length-1})\")\n",
    "\n",
    "\n",
    "train_end_idx = n_train_samples\n",
    "\n",
    "val_start_idx = train_end_idx\n",
    "val_end_idx = val_start_idx + n_val_samples\n",
    "\n",
    "# Test: empieza donde termina val\n",
    "test_start_idx = val_end_idx\n",
    "test_end_idx = test_start_idx + n_test_samples\n",
    "\n",
    "train_idxs = list(range(0, train_end_idx))\n",
    "val_idxs = list(range(val_start_idx, val_end_idx))\n",
    "test_idxs = list(range(test_start_idx, test_end_idx))\n",
    "\n",
    "print(f\"\\nÍndices de split:\")\n",
    "print(f\"  Train: {0} → {train_end_idx-1} ({len(train_idxs)} samples)\")\n",
    "print(f\"  Val:   {val_start_idx} → {val_end_idx-1} ({len(val_idxs)} samples)\")\n",
    "print(f\"  Test:  {test_start_idx} → {test_end_idx-1} ({len(test_idxs)} samples)\")\n",
    "print(f\"  Total: {len(train_idxs) + len(val_idxs) + len(test_idxs)} samples\")\n",
    "\n",
    "# Verificación\n",
    "assert len(train_idxs) == n_train_samples, \"❌ Train samples no coinciden\"\n",
    "assert len(val_idxs) == n_val_samples, \"❌ Val samples no coinciden\"\n",
    "assert len(test_idxs) == n_test_samples, \"❌ Test samples no coinciden\"\n",
    "print(\"\\nVerificación de índices: CORRECTA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b8bea7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CREAR SPLITTER Y DATAMODULE\n",
      "======================================================================\n",
      "Splitter manual creado\n",
      "DataModule creado y configurado\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 12: CREAR SPLITTER Y DATAMODULE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREAR SPLITTER Y DATAMODULE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class ManualSplitter:\n",
    "    \"\"\"Splitter que respeta la estratificación temporal\"\"\"\n",
    "    def __init__(self, train_idxs, val_idxs, test_idxs):\n",
    "        self.train_idxs = train_idxs\n",
    "        self.val_idxs = val_idxs\n",
    "        self.test_idxs = test_idxs\n",
    "    \n",
    "    def split(self, dataset, **kwargs):\n",
    "        return self.train_idxs, self.val_idxs, self.test_idxs\n",
    "\n",
    "manual_splitter = ManualSplitter(train_idxs, val_idxs, test_idxs)\n",
    "print(\"Splitter manual creado\")\n",
    "\n",
    "\n",
    "# Descomenta cuando tengas tsl disponible\n",
    "from tsl.data import SpatioTemporalDataModule\n",
    "\n",
    "# Fijar semilla antes de crear DataModule\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "dm_norm = SpatioTemporalDataModule(\n",
    "    dataset=torch_dataset_norm,  # ✅ UN SOLO dataset, NO ConcatDataset\n",
    "    scalers=None,  # Ya normalizados\n",
    "    splitter=manual_splitter,\n",
    "    batch_size=32,\n",
    "    workers=0,\n",
    ")\n",
    "\n",
    "dm_norm.setup()\n",
    "\n",
    "print(\"DataModule creado y configurado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9cbab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICACIÓN FINAL\n",
      "======================================================================\n",
      "\n",
      "IMPORTANCIA DE ESTRATIFICACIÓN PRESERVADA:\n",
      "  1. ✓ Datos divididos por pozo (70/15/15%)\n",
      "  2. ✓ Normalización con scalers SOLO de train\n",
      "  3. ✓ Tensores concatenados EN ORDEN (train→val→test)\n",
      "  4. ✓ UN SOLO SpatioTemporalDataset (no ConcatDataset)\n",
      "  5. ✓ Índices calculados para respetar límites originales\n",
      "  6. ✓ ManualSplitter preserva la estratificación\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VERIFICACIÓN FINAL DE ESTRATIFICACIÓN\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VERIFICACIÓN FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nIMPORTANCIA DE ESTRATIFICACIÓN PRESERVADA:\")\n",
    "print(\"  1. ✓ Datos divididos por pozo (70/15/15%)\")\n",
    "print(\"  2. ✓ Normalización con scalers SOLO de train\")\n",
    "print(\"  3. ✓ Tensores concatenados EN ORDEN (train→val→test)\")\n",
    "print(\"  4. ✓ UN SOLO SpatioTemporalDataset (no ConcatDataset)\")\n",
    "print(\"  5. ✓ Índices calculados para respetar límites originales\")\n",
    "print(\"  6. ✓ ManualSplitter preserva la estratificación\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe3cd3",
   "metadata": {},
   "source": [
    "## TIMETHENSPACE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "181e3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "# ============================================================================\n",
    "# DEFINIR MODELO TIMETHENSPACE\n",
    "# ============================================================================\n",
    "class TimeThenSpaceModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 edge_index, edge_weight,\n",
    "                 hidden_size: int = 96,\n",
    "                 rnn_layers: int = 3,\n",
    "                 gnn_kernel: int = 5,\n",
    "                 dropout: float = 0.05,\n",
    "                 output_size: int = 3):\n",
    "        super(TimeThenSpaceModel, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size      # 8 features de entrada\n",
    "        self.output_size = output_size    # 3 features de salida (Oil, Gas, Water)\n",
    "        self.horizon = horizon            # 7 días a predecir\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_nodes = n_nodes            # 4 pozos\n",
    "        \n",
    "        # Encoder: input_size → hidden_size\n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Node embeddings\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes, hidden_size)\n",
    "        \n",
    "        # Módulo temporal (RNN)\n",
    "        self.time_nn = RNN(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=rnn_layers,\n",
    "            cell='gru',\n",
    "            return_only_last_state=True\n",
    "        )\n",
    "        \n",
    "        # Módulo espacial (Graph Convolution)\n",
    "        self.space_nn = DiffConv(\n",
    "            in_channels=hidden_size,\n",
    "            out_channels=hidden_size,\n",
    "            k=gnn_kernel\n",
    "        )\n",
    "        \n",
    "        # Decoder: hidden_size → output_size * horizon\n",
    "        self.decoder = nn.Linear(hidden_size, output_size * horizon)\n",
    "        \n",
    "        # Rearrange: (batch, nodes, horizon*output) → (batch, horizon, nodes, output)\n",
    "        self.rearrange = Rearrange('b n (t f) -> b t n f', t=horizon, f=output_size)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Registrar grafo como buffers\n",
    "        self.register_buffer('edge_index', edge_index)\n",
    "        self.register_buffer('edge_weight', edge_weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch, window, nodes, input_size] \n",
    "               Ejemplo: [32, 14, 4, 8]\n",
    "        \n",
    "        Returns:\n",
    "            out: [batch, horizon, nodes, output_size]\n",
    "                 Ejemplo: [32, 7, 4, 3]\n",
    "        \"\"\"\n",
    "        # Encoder: [b, w, n, 8] → [b, w, n, hidden]\n",
    "        x_enc = self.encoder(x)\n",
    "        \n",
    "        # Add node embeddings: [b, w, n, hidden]\n",
    "        x_emb = x_enc + self.node_embeddings()\n",
    "        \n",
    "        # Temporal processing: [b, w, n, hidden] → [b, n, hidden]\n",
    "        h = self.time_nn(x_emb)\n",
    "        \n",
    "        # Spatial processing: [b, n, hidden] → [b, n, hidden]\n",
    "        z = self.space_nn(h, self.edge_index, self.edge_weight)\n",
    "        \n",
    "        # Dropout\n",
    "        z = self.dropout(z)\n",
    "        \n",
    "        # Decoder: [b, n, hidden] → [b, n, horizon*output]\n",
    "        # Ejemplo: [32, 4, 96] → [32, 4, 21]\n",
    "        x_out = self.decoder(z)\n",
    "        \n",
    "        # Rearrange: [b, n, 21] → [b, 7, 4, 3]\n",
    "        x_horizon = self.rearrange(x_out)\n",
    "        \n",
    "        return x_horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Edge index tensor shape: torch.Size([2, 6])\n",
      "Edge weight shape: torch.Size([6])\n",
      "Edge index:\n",
      "tensor([[0, 0, 1, 1, 2, 2],\n",
      "        [1, 2, 0, 2, 0, 1]])\n",
      "TimeThenSpaceModel(\n",
      "  (encoder): Linear(in_features=8, out_features=128, bias=True)\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=3, embedding_size=128)\n",
      "  (time_nn): RNN(\n",
      "    (rnn): GRU(128, 128, num_layers=4)\n",
      "  )\n",
      "  (space_nn): DiffConv(128, 128)\n",
      "  (decoder): Linear(in_features=128, out_features=21, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=7, f=3)\n",
      "  (dropout): Dropout(p=0.05, inplace=False)\n",
      ")\n",
      "==========================================================\n",
      "Number of model (TimeThenSpaceModel) parameters:    548117\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5B. RECREAR EDGE_INDEX CORRECTAMENTE\n",
    "# ============================================================================\n",
    "src_nodes = []\n",
    "dst_nodes = []\n",
    "weights = []\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if i != j:\n",
    "            src_nodes.append(i)\n",
    "            dst_nodes.append(j)\n",
    "            weights.append(adj_matrix[i, j])\n",
    "\n",
    "# Crear tensores\n",
    "edge_index_tensor = torch.tensor([src_nodes, dst_nodes], dtype=torch.long)  # [2, 12]\n",
    "edge_weight = torch.tensor(weights, dtype=torch.float32)  # [12]\n",
    "\n",
    "print(f\"\\nEdge index tensor shape: {edge_index_tensor.shape}\")  # [2, 12]\n",
    "print(f\"Edge weight shape: {edge_weight.shape}\")  # [12]\n",
    "print(f\"Edge index:\\n{edge_index_tensor}\")\n",
    "model = TimeThenSpaceModel(\n",
    "    input_size=8,           # 8 features de entrada\n",
    "    output_size=3,          # 3 features de salida (Oil, Gas, Water)\n",
    "    n_nodes=3,              # 4 pozos\n",
    "    horizon=7,              # Predecir 7 días\n",
    "    edge_index=edge_index_tensor,       # Tensor de aristas [12, 2]\n",
    "    edge_weight=edge_weight, # Pesos de las aristas\n",
    "    hidden_size=128,\n",
    "    rnn_layers=4,\n",
    "    gnn_kernel=4,\n",
    ")\n",
    "print(model)\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)\n",
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947e3efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE          | 0      | train\n",
      "1 | train_metrics | MetricCollection   | 0      | train\n",
      "2 | val_metrics   | MetricCollection   | 0      | train\n",
      "3 | test_metrics  | MetricCollection   | 0      | train\n",
      "4 | model         | TimeThenSpaceModel | 548 K  | train\n",
      "-------------------------------------------------------------\n",
      "548 K     Trainable params\n",
      "0         Non-trainable params\n",
      "548 K     Total params\n",
      "2.192     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento TimeThenSpace para Kyle Field...\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['edge_index', 'edge_weight'] are filtered out. Only args ['x'] are forwarded to the model (TimeThenSpaceModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 125/125 [00:13<00:00,  9.34it/s, v_num=42, val_mae=0.518, val_mse=0.711, val_r2=0.388, train_mae=0.634, train_mse=0.836, train_r2=0.161]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved. New best score: 0.518\n",
      "Epoch 0, global step 125: 'val_mae' reached 0.51799 (best 0.51799), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=00-val_mae=0.5180.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 125/125 [00:13<00:00,  9.20it/s, v_num=42, val_mae=0.380, val_mse=0.493, val_r2=0.561, train_mae=0.410, train_mse=0.485, train_r2=0.512]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.138 >= min_delta = 0.01. New best score: 0.380\n",
      "Epoch 1, global step 250: 'val_mae' reached 0.38028 (best 0.38028), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=01-val_mae=0.3803.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [00:15<00:00,  8.04it/s, v_num=42, val_mae=0.314, val_mse=0.435, val_r2=0.612, train_mae=0.312, train_mse=0.362, train_r2=0.637]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.066 >= min_delta = 0.01. New best score: 0.314\n",
      "Epoch 2, global step 375: 'val_mae' reached 0.31403 (best 0.31403), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=02-val_mae=0.3140.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 125/125 [00:14<00:00,  8.55it/s, v_num=42, val_mae=0.285, val_mse=0.412, val_r2=0.633, train_mae=0.278, train_mse=0.333, train_r2=0.664]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.029 >= min_delta = 0.01. New best score: 0.285\n",
      "Epoch 3, global step 500: 'val_mae' reached 0.28547 (best 0.28547), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=03-val_mae=0.2855.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 125/125 [00:14<00:00,  8.67it/s, v_num=42, val_mae=0.273, val_mse=0.402, val_r2=0.641, train_mae=0.265, train_mse=0.323, train_r2=0.674]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.012 >= min_delta = 0.01. New best score: 0.273\n",
      "Epoch 4, global step 625: 'val_mae' reached 0.27346 (best 0.27346), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=04-val_mae=0.2735.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 125/125 [00:14<00:00,  8.60it/s, v_num=42, val_mae=0.274, val_mse=0.391, val_r2=0.651, train_mae=0.257, train_mse=0.318, train_r2=0.680]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 750: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 125/125 [00:18<00:00,  6.77it/s, v_num=42, val_mae=0.266, val_mse=0.393, val_r2=0.649, train_mae=0.254, train_mse=0.316, train_r2=0.681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 875: 'val_mae' reached 0.26642 (best 0.26642), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=06-val_mae=0.2664.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 125/125 [00:15<00:00,  8.20it/s, v_num=42, val_mae=0.260, val_mse=0.389, val_r2=0.653, train_mae=0.250, train_mse=0.313, train_r2=0.684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.013 >= min_delta = 0.01. New best score: 0.260\n",
      "Epoch 7, global step 1000: 'val_mae' reached 0.26009 (best 0.26009), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=07-val_mae=0.2601.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 125/125 [00:14<00:00,  8.51it/s, v_num=42, val_mae=0.260, val_mse=0.389, val_r2=0.653, train_mae=0.246, train_mse=0.311, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1125: 'val_mae' reached 0.25991 (best 0.25991), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=08-val_mae=0.2599.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 125/125 [00:17<00:00,  7.22it/s, v_num=42, val_mae=0.255, val_mse=0.385, val_r2=0.656, train_mae=0.243, train_mse=0.311, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1250: 'val_mae' reached 0.25497 (best 0.25497), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=09-val_mae=0.2550.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 125/125 [00:14<00:00,  8.53it/s, v_num=42, val_mae=0.251, val_mse=0.387, val_r2=0.655, train_mae=0.238, train_mse=0.308, train_r2=0.691]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1375: 'val_mae' reached 0.25101 (best 0.25101), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=10-val_mae=0.2510.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 125/125 [00:18<00:00,  6.82it/s, v_num=42, val_mae=0.252, val_mse=0.385, val_r2=0.656, train_mae=0.235, train_mse=0.308, train_r2=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1500: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 125/125 [00:16<00:00,  7.52it/s, v_num=42, val_mae=0.255, val_mse=0.383, val_r2=0.658, train_mae=0.231, train_mse=0.307, train_r2=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 125/125 [00:15<00:00,  8.02it/s, v_num=42, val_mae=0.248, val_mse=0.385, val_r2=0.656, train_mae=0.230, train_mse=0.306, train_r2=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.012 >= min_delta = 0.01. New best score: 0.248\n",
      "Epoch 13, global step 1750: 'val_mae' reached 0.24827 (best 0.24827), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=13-val_mae=0.2483.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 125/125 [00:17<00:00,  6.97it/s, v_num=42, val_mae=0.248, val_mse=0.386, val_r2=0.656, train_mae=0.228, train_mse=0.306, train_r2=0.692]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1875: 'val_mae' reached 0.24810 (best 0.24810), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=14-val_mae=0.2481.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 125/125 [00:14<00:00,  8.75it/s, v_num=42, val_mae=0.246, val_mse=0.386, val_r2=0.656, train_mae=0.227, train_mse=0.305, train_r2=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 2000: 'val_mae' reached 0.24626 (best 0.24626), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=15-val_mae=0.2463.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 125/125 [00:18<00:00,  6.87it/s, v_num=42, val_mae=0.250, val_mse=0.385, val_r2=0.657, train_mae=0.225, train_mse=0.305, train_r2=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 125/125 [00:19<00:00,  6.32it/s, v_num=42, val_mae=0.248, val_mse=0.385, val_r2=0.656, train_mae=0.224, train_mse=0.305, train_r2=0.693]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 2250: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 125/125 [00:14<00:00,  8.58it/s, v_num=42, val_mae=0.247, val_mse=0.388, val_r2=0.654, train_mae=0.223, train_mse=0.304, train_r2=0.695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 2375: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 125/125 [00:21<00:00,  5.75it/s, v_num=42, val_mae=0.244, val_mse=0.386, val_r2=0.656, train_mae=0.222, train_mse=0.304, train_r2=0.694]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 2500: 'val_mae' reached 0.24387 (best 0.24387), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=19-val_mae=0.2439.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 125/125 [00:14<00:00,  8.48it/s, v_num=42, val_mae=0.256, val_mse=0.383, val_r2=0.658, train_mae=0.221, train_mse=0.303, train_r2=0.695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 2625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 125/125 [00:13<00:00,  9.33it/s, v_num=42, val_mae=0.245, val_mse=0.384, val_r2=0.657, train_mae=0.220, train_mse=0.302, train_r2=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 2750: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 125/125 [00:12<00:00,  9.96it/s, v_num=42, val_mae=0.245, val_mse=0.385, val_r2=0.657, train_mae=0.219, train_mse=0.302, train_r2=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 2875: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 125/125 [00:13<00:00,  9.38it/s, v_num=42, val_mae=0.244, val_mse=0.387, val_r2=0.654, train_mae=0.219, train_mse=0.302, train_r2=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 3000: 'val_mae' reached 0.24366 (best 0.24366), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=23-val_mae=0.2437.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 125/125 [00:13<00:00,  8.93it/s, v_num=42, val_mae=0.249, val_mse=0.384, val_r2=0.657, train_mae=0.218, train_mse=0.302, train_r2=0.696]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 3125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 125/125 [00:15<00:00,  8.15it/s, v_num=42, val_mae=0.250, val_mse=0.380, val_r2=0.661, train_mae=0.218, train_mse=0.302, train_r2=0.697]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 3250: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 125/125 [00:16<00:00,  7.69it/s, v_num=42, val_mae=0.258, val_mse=0.380, val_r2=0.660, train_mae=0.217, train_mse=0.301, train_r2=0.697]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 3375: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 125/125 [00:14<00:00,  8.49it/s, v_num=42, val_mae=0.242, val_mse=0.383, val_r2=0.659, train_mae=0.217, train_mse=0.300, train_r2=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 3500: 'val_mae' reached 0.24206 (best 0.24206), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-timespace-epoch=27-val_mae=0.2421-v1.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 125/125 [00:14<00:00,  8.50it/s, v_num=42, val_mae=0.244, val_mse=0.383, val_r2=0.658, train_mae=0.216, train_mse=0.301, train_r2=0.698]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mae did not improve in the last 15 records. Best score: 0.248. Signaling Trainer to stop.\n",
      "Epoch 28, global step 3625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 125/125 [00:14<00:00,  8.49it/s, v_num=42, val_mae=0.244, val_mse=0.383, val_r2=0.658, train_mae=0.216, train_mse=0.301, train_r2=0.698]\n",
      "Testing DataLoader 0: 100%|██████████| 42/42 [00:01<00:00, 27.01it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.09320951998233795\n",
      "        test_mae            0.09320952743291855\n",
      "        test_mse            0.07947178184986115\n",
      "         test_r2             0.925626277923584\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Resultados finales TimeThenSpace:\n",
      "test_mae: 0.0932\n",
      "test_mse: 0.0795\n",
      "test_r2: 0.9256\n",
      "test_loss: 0.0932\n"
     ]
    }
   ],
   "source": [
    "class MaskedR2(nn.Module):\n",
    "    \"\"\"R² Score with mask support\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, y_hat, y, mask=None):\n",
    "        if mask is None:\n",
    "            mask = torch.ones_like(y, dtype=torch.bool)\n",
    "        \n",
    "        y_hat_masked = y_hat[mask]\n",
    "        y_masked = y[mask]\n",
    "        \n",
    "        ss_res = torch.sum((y_masked - y_hat_masked) ** 2)\n",
    "        y_mean = torch.mean(y_masked)\n",
    "        ss_tot = torch.sum((y_masked - y_mean) ** 2)\n",
    "        \n",
    "        if ss_tot == 0:\n",
    "            return torch.tensor(0.0, device=y.device)\n",
    "        \n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        return r2\n",
    "\n",
    "\n",
    "# Crear predictor con métricas\n",
    "predictor = Predictor(\n",
    "    model=model,\n",
    "    optim_class=torch.optim.AdamW,\n",
    "    optim_kwargs={'lr': 0.00005, 'weight_decay': 0.0001},\n",
    "    loss_fn=MaskedMAE(),\n",
    "    metrics={\n",
    "        'mae': MaskedMAE(),      \n",
    "        'mse': MaskedMSE(),     \n",
    "        'r2': MaskedR2()\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Checkpoint optimizado para Kyle Field\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='logs/kyle_field',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',              \n",
    "    mode='min',\n",
    "    filename='kyle-timespace-{epoch:02d}-{val_mae:.4f}',\n",
    "    save_weights_only=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Early stopping para evitar overfitting\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_mae',              # Monitorear MAE en lugar de MAPE\n",
    "    patience=15,                    \n",
    "    min_delta=0.01,                \n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Trainer optimizado para Kyle Field\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=100,                 \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,         \n",
    "    limit_train_batches=None,       \n",
    "    val_check_interval=1.0,         \n",
    "    log_every_n_steps=5,            \n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    deterministic=True,            \n",
    "    benchmark=False                  \n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento TimeThenSpace para Kyle Field...\")\n",
    "trainer.fit(predictor, datamodule=dm_norm)\n",
    "\n",
    "# Evaluación final\n",
    "test_results = trainer.test(predictor, datamodule=dm_norm)\n",
    "print(\"\\nResultados finales TimeThenSpace:\")\n",
    "for metric, value in test_results[0].items():\n",
    "    if 'mape' not in metric.lower(): \n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de1bff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_all_sets_manual(predictor, dm_norm, train_tensor, full_target, train_length, val_length):\n",
    "\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"EVALUACIÓN COMPLETA: TRAIN, VAL y TEST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RECREAR SCALERS\n",
    "    # ========================================================================\n",
    "    print(\"\\n[0/5] Recreando scalers desde datos de train...\")\n",
    "    \n",
    "    target_names = ['Oil (m3)', 'Gas (m3)', 'Produced Water (m3)']\n",
    "    y_scalers = []\n",
    "    \n",
    "    # IMPORTANTE: Los scalers se ajustan SOLO con datos de train\n",
    "    for feat_idx in range(3):\n",
    "        scaler = StandardScaler()\n",
    "        # full_target[:train_length] son los datos de TRAIN\n",
    "        train_target_feat = full_target[:train_length, :, feat_idx].numpy()\n",
    "        train_target_flat = train_target_feat.reshape(-1, 1)\n",
    "        scaler.fit(train_target_flat)\n",
    "        y_scalers.append(scaler)\n",
    "        \n",
    "        print(f\"  Scaler {feat_idx} ({target_names[feat_idx]}): \"\n",
    "              f\"mean={scaler.mean_[0]:.4f}, std={scaler.scale_[0]:.4f}\")\n",
    "    \n",
    "    print(\"✓ Scalers recreados con datos de TRAIN\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # FUNCIÓN AUXILIAR: EVALUAR UN CONJUNTO\n",
    "    # ========================================================================\n",
    "    def evaluate_single_set(dataloader, set_name):\n",
    "        \"\"\"Evalúa un conjunto específico\"\"\"\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"EVALUANDO: {set_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        model = predictor.model\n",
    "        model.eval()\n",
    "        \n",
    "        predictions_norm = []\n",
    "        targets_norm = []\n",
    "        \n",
    "        print(f\"\\n[1/4] Obteniendo predicciones de {set_name}...\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in dataloader:\n",
    "                y_pred = model(batch.x)\n",
    "                predictions_norm.append(y_pred.detach().cpu())\n",
    "                targets_norm.append(batch.y.detach().cpu())\n",
    "        \n",
    "        predictions_norm = torch.cat(predictions_norm, dim=0)\n",
    "        targets_norm = torch.cat(targets_norm, dim=0)\n",
    "        \n",
    "        print(f\"✓ Predicciones: {predictions_norm.shape}\")\n",
    "        print(f\"  Nota: Están en escala NORMALIZADA\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # DESNORMALIZAR\n",
    "        # ====================================================================\n",
    "        print(f\"\\n[2/4] Desnormalizando...\")\n",
    "        \n",
    "        S, H, N, F = predictions_norm.shape\n",
    "        pred_flat = predictions_norm.reshape(-1, F).numpy()\n",
    "        target_flat = targets_norm.reshape(-1, F).numpy()\n",
    "        \n",
    "        pred_desnorm = np.zeros_like(pred_flat)\n",
    "        target_desnorm = np.zeros_like(target_flat)\n",
    "        \n",
    "        # Desnormalizar cada feature\n",
    "        for feat_idx in range(F):\n",
    "            pred_desnorm[:, feat_idx] = y_scalers[feat_idx].inverse_transform(\n",
    "                pred_flat[:, feat_idx].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "            target_desnorm[:, feat_idx] = y_scalers[feat_idx].inverse_transform(\n",
    "                target_flat[:, feat_idx].reshape(-1, 1)\n",
    "            ).flatten()\n",
    "        \n",
    "        print(f\"✓ Desnormalizado (aún con log): [{pred_desnorm.min():.2f}, {pred_desnorm.max():.2f}]\")\n",
    "        \n",
    "        # ====================================================================\n",
    "        # INVERTIR LOG-TRANSFORM\n",
    "        # ====================================================================\n",
    "        print(f\"\\n[3/4] Invirtiendo log-transform (np.expm1)...\")\n",
    "        \n",
    "        # np.expm1(x) = exp(x) - 1, que invierte np.log1p(x)\n",
    "        predictions_original = np.expm1(pred_desnorm)\n",
    "        targets_original = np.expm1(target_desnorm)\n",
    "        \n",
    "        # Asegurar que no hay valores negativos\n",
    "        predictions_original = np.maximum(predictions_original, 0)\n",
    "        targets_original = np.maximum(targets_original, 0)\n",
    "        \n",
    "        print(f\"✓ Escala original (m³): [{predictions_original.min():.2f}, {predictions_original.max():.2f}]\")\n",
    "        \n",
    "        # Verificación de sanidad\n",
    "        if targets_original.max() > 2e6:\n",
    "            print(f\"\\n🚨 ERROR: Max target={targets_original.max():.2e} m³\")\n",
    "            print(f\"   Esto es anormalmente alto, puede haber un error en la desnormalización\")\n",
    "            return None\n",
    "        \n",
    "        # ====================================================================\n",
    "        # CALCULAR MÉTRICAS\n",
    "        # ====================================================================\n",
    "        print(f\"\\n[4/4] Calculando métricas...\")\n",
    "        \n",
    "        epsilon = 1e-8\n",
    "        \n",
    "        # MAE (Mean Absolute Error)\n",
    "        mae = np.mean(np.abs(targets_original - predictions_original))\n",
    "        \n",
    "        # MAPE (Mean Absolute Percentage Error) - evitar división por cero\n",
    "        mask_mape = targets_original > 0.1\n",
    "        mape = np.mean(np.abs((targets_original[mask_mape] - predictions_original[mask_mape]) / \n",
    "                       targets_original[mask_mape])) * 100 if mask_mape.sum() > 0 else 0\n",
    "        \n",
    "        # SMAPE (Symmetric Mean Absolute Percentage Error)\n",
    "        smape = np.mean(2 * np.abs(targets_original - predictions_original) / \n",
    "                        (np.abs(targets_original) + np.abs(predictions_original) + epsilon)) * 100\n",
    "        \n",
    "        # WMAPE (Weighted Mean Absolute Percentage Error)\n",
    "        wmape = (np.sum(np.abs(targets_original - predictions_original)) / \n",
    "                 (np.sum(np.abs(targets_original)) + epsilon)) * 100\n",
    "        \n",
    "        # MAPE con umbral (solo para valores > 10)\n",
    "        mask_mape_10 = targets_original > 10\n",
    "        mape_10 = np.mean(np.abs((targets_original[mask_mape_10] - predictions_original[mask_mape_10]) / \n",
    "                          targets_original[mask_mape_10])) * 100 if mask_mape_10.sum() > 0 else 0\n",
    "        \n",
    "        # RMSE (Root Mean Squared Error)\n",
    "        rmse = np.sqrt(np.mean((targets_original - predictions_original) ** 2))\n",
    "        \n",
    "        # R² (Coefficient of Determination)\n",
    "        ss_res = np.sum((targets_original - predictions_original) ** 2)\n",
    "        ss_tot = np.sum((targets_original - np.mean(targets_original)) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "        \n",
    "        # Métricas para producción activa (> 10 m³)\n",
    "        active_mask = targets_original > 10\n",
    "        active_count = active_mask.sum()\n",
    "        \n",
    "        if active_count > 0:\n",
    "            mae_active = np.mean(np.abs(targets_original[active_mask] - predictions_original[active_mask]))\n",
    "            r2_active = r2_score(targets_original[active_mask], predictions_original[active_mask])\n",
    "        else:\n",
    "            mae_active = 0\n",
    "            r2_active = 0\n",
    "        \n",
    "        # ====================================================================\n",
    "        # IMPRIMIR RESULTADOS\n",
    "        # ====================================================================\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"MÉTRICAS: {set_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"\\n📊 MÉTRICAS GLOBALES:\")\n",
    "        print(f\"  MAE:        {mae:>10.2f} m³\")\n",
    "        print(f\"  RMSE:       {rmse:>10.2f} m³\")\n",
    "        print(f\"  R²:         {r2:>10.4f}\")\n",
    "        print(f\"  WMAPE:      {wmape:>10.2f} %\")\n",
    "        print(f\"  SMAPE:      {smape:>10.2f} %\")\n",
    "        print(f\"  MAPE (>10): {mape_10:>10.2f} %\")\n",
    "        \n",
    "        print(f\"\\n📊 PRODUCCIÓN ACTIVA (> 10 m³):\")\n",
    "        print(f\"  Registros: {active_count:,}\")\n",
    "        print(f\"  MAE:       {mae_active:>10.2f} m³\")\n",
    "        print(f\"  R²:        {r2_active:>10.4f}\")\n",
    "        \n",
    "        # Métricas por variable\n",
    "        pred_reshaped = predictions_original.reshape(S, H, N, F)\n",
    "        target_reshaped = targets_original.reshape(S, H, N, F)\n",
    "        \n",
    "        print(f\"\\n📊 MÉTRICAS POR VARIABLE:\")\n",
    "        print(f\"{'Variable':<20} {'MAE (m³)':<12} {'WMAPE (%)':<10} {'R²':<10}\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        metrics_by_var = {}\n",
    "        \n",
    "        for feat_idx, var_name in enumerate(target_names):\n",
    "            pred_var = pred_reshaped[:, :, :, feat_idx].flatten()\n",
    "            target_var = target_reshaped[:, :, :, feat_idx].flatten()\n",
    "            \n",
    "            mae_var = np.mean(np.abs(target_var - pred_var))\n",
    "            wmape_var = (np.sum(np.abs(target_var - pred_var)) / \n",
    "                        (np.sum(np.abs(target_var)) + epsilon)) * 100\n",
    "            \n",
    "            ss_res_var = np.sum((target_var - pred_var) ** 2)\n",
    "            ss_tot_var = np.sum((target_var - np.mean(target_var)) ** 2)\n",
    "            r2_var = 1 - (ss_res_var / ss_tot_var) if ss_tot_var > 0 else 0\n",
    "            \n",
    "            print(f\"{var_name:<20} {mae_var:<12.2f} {wmape_var:<10.2f} {r2_var:<10.4f}\")\n",
    "            \n",
    "            metrics_by_var[var_name] = {\n",
    "                'mae': mae_var,\n",
    "                'wmape': wmape_var,\n",
    "                'r2': r2_var\n",
    "            }\n",
    "        \n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        return {\n",
    "            'mae': mae,\n",
    "            'mape': mape,\n",
    "            'mape_10': mape_10,\n",
    "            'smape': smape,\n",
    "            'wmape': wmape,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "            'mae_active': mae_active,\n",
    "            'r2_active': r2_active,\n",
    "            'active_count': active_count,\n",
    "            'metrics_by_var': metrics_by_var,\n",
    "            'predictions': predictions_original,\n",
    "            'targets': targets_original\n",
    "        }\n",
    "    \n",
    "    # ========================================================================\n",
    "    # EVALUAR CADA CONJUNTO\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EVALUANDO TODOS LOS CONJUNTOS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    train_metrics = evaluate_single_set(dm_norm.train_dataloader(), \"TRAIN\")\n",
    "    val_metrics = evaluate_single_set(dm_norm.val_dataloader(), \"VALIDATION\")\n",
    "    test_metrics = evaluate_single_set(dm_norm.test_dataloader(), \"TEST\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # COMPARACIÓN FINAL\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARACIÓN: TRAIN vs VAL vs TEST\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\n{'Métrica':<15} {'TRAIN':<15} {'VAL':<15} {'TEST':<15}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    metrics_to_compare = ['r2', 'mae', 'wmape', 'rmse']\n",
    "    metric_names = ['R²', 'MAE (m³)', 'WMAPE (%)', 'RMSE (m³)']\n",
    "    \n",
    "    for metric_key, metric_name in zip(metrics_to_compare, metric_names):\n",
    "        train_val = train_metrics[metric_key]\n",
    "        val_val = val_metrics[metric_key]\n",
    "        test_val = test_metrics[metric_key]\n",
    "        print(f\"{metric_name:<15} {train_val:<15.2f} {val_val:<15.2f} {test_val:<15.2f}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # ANÁLISIS DE OVERFITTING\n",
    "    # ========================================================================\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ANÁLISIS DE OVERFITTING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    train_r2 = train_metrics['r2']\n",
    "    val_r2 = val_metrics['r2']\n",
    "    test_r2 = test_metrics['r2']\n",
    "    \n",
    "    print(f\"\\nR² por conjunto:\")\n",
    "    print(f\"  Train: {train_r2:.4f}\")\n",
    "    print(f\"  Val:   {val_r2:.4f}\")\n",
    "    print(f\"  Test:  {test_r2:.4f}\")\n",
    "    \n",
    "    diff_train_val = train_r2 - val_r2\n",
    "    diff_val_test = abs(val_r2 - test_r2)\n",
    "    \n",
    "    if diff_train_val > 0.10:\n",
    "        print(f\"\\n⚠️  POSIBLE OVERFITTING:\")\n",
    "        print(f\"   Diferencia Train-Val: {diff_train_val:.4f} (>0.10)\")\n",
    "        print(f\"   El modelo se ajusta demasiado a los datos de entrenamiento\")\n",
    "    elif abs(diff_train_val) < 0.05:\n",
    "        print(f\"\\n✅ BUEN BALANCE:\")\n",
    "        print(f\"   Diferencia Train-Val: {abs(diff_train_val):.4f} (<0.05)\")\n",
    "        print(f\"   El modelo generaliza bien\")\n",
    "    else:\n",
    "        print(f\"\\n✅ ACEPTABLE:\")\n",
    "        print(f\"   Diferencia Train-Val: {abs(diff_train_val):.4f}\")\n",
    "    \n",
    "    if diff_val_test > 0.05:\n",
    "        print(f\"\\n⚠️  Diferencia Val-Test: {diff_val_test:.4f}\")\n",
    "        print(f\"   Posible variabilidad en distribución de datos\")\n",
    "    else:\n",
    "        print(f\"\\n✅ Val y Test consistentes: diff={diff_val_test:.4f}\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # RETORNAR RESULTADOS\n",
    "    # ========================================================================\n",
    "    \n",
    "    return {\n",
    "        'train': train_metrics,\n",
    "        'val': val_metrics,\n",
    "        'test': test_metrics\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2f6b29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN COMPLETA: TRAIN, VAL y TEST\n",
      "================================================================================\n",
      "\n",
      "[0/5] Recreando scalers desde datos de train...\n",
      "  Scaler 0 (Oil (m3)): mean=4.0149, std=2.7042\n",
      "  Scaler 1 (Gas (m3)): mean=8.0968, std=5.4370\n",
      "  Scaler 2 (Produced Water (m3)): mean=1.2803, std=2.0721\n",
      "✓ Scalers recreados con datos de TRAIN\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO TODOS LOS CONJUNTOS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TRAIN\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TRAIN...\n",
      "✓ Predicciones: torch.Size([4000, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-1.84, 13.72]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 908985.19]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TRAIN\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          18344.75 m³\n",
      "  RMSE:         66701.10 m³\n",
      "  R²:             0.7148\n",
      "  WMAPE:           40.70 %\n",
      "  SMAPE:           94.64 %\n",
      "  MAPE (>10):     116.96 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 138,477\n",
      "  MAE:         29599.78 m³\n",
      "  R²:            0.7201\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             78.36        28.03      0.7322    \n",
      "Gas (m3)             54938.60     40.73      0.6153    \n",
      "Produced Water (m3)  17.28        40.75      0.5629    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de VALIDATION...\n",
      "✓ Predicciones: torch.Size([1424, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-1.27, 12.62]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 301236.12]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           8303.66 m³\n",
      "  RMSE:         31306.63 m³\n",
      "  R²:             0.5835\n",
      "  WMAPE:           59.90 %\n",
      "  SMAPE:          129.32 %\n",
      "  MAPE (>10):     145.06 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,257\n",
      "  MAE:         18505.42 m³\n",
      "  R²:            0.6076\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             40.83        31.50      0.8027    \n",
      "Gas (m3)             24848.20     59.99      0.5034    \n",
      "Produced Water (m3)  21.95        51.43      0.6623    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TEST\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TEST...\n",
      "✓ Predicciones: torch.Size([1316, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.57, 12.47]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 259551.16]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TEST\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           8207.75 m³\n",
      "  RMSE:         30595.41 m³\n",
      "  R²:             0.6461\n",
      "  WMAPE:           48.23 %\n",
      "  SMAPE:          123.31 %\n",
      "  MAPE (>10):      47.00 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,117\n",
      "  MAE:         20234.28 m³\n",
      "  R²:            0.5805\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             18.31        17.68      0.9182    \n",
      "Gas (m3)             24594.57     48.30      0.5478    \n",
      "Produced Water (m3)  10.37        30.41      0.8105    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPARACIÓN: TRAIN vs VAL vs TEST\n",
      "================================================================================\n",
      "\n",
      "Métrica         TRAIN           VAL             TEST           \n",
      "-----------------------------------------------------------------\n",
      "R²              0.71            0.58            0.65           \n",
      "MAE (m³)        18344.75        8303.66         8207.75        \n",
      "WMAPE (%)       40.70           59.90           48.23          \n",
      "RMSE (m³)       66701.10        31306.63        30595.41       \n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE OVERFITTING\n",
      "================================================================================\n",
      "\n",
      "R² por conjunto:\n",
      "  Train: 0.7148\n",
      "  Val:   0.5835\n",
      "  Test:  0.6461\n",
      "\n",
      "⚠️  POSIBLE OVERFITTING:\n",
      "   Diferencia Train-Val: 0.1313 (>0.10)\n",
      "   El modelo se ajusta demasiado a los datos de entrenamiento\n",
      "\n",
      "⚠️  Diferencia Val-Test: 0.0625\n",
      "   Posible variabilidad en distribución de datos\n",
      "================================================================================\n",
      "\n",
      "📊 RESUMEN TIME THEN SPACE:\n",
      "\n",
      "TRAIN:\n",
      "  R²:    0.7148\n",
      "  WMAPE: 40.70%\n",
      "\n",
      "VAL:\n",
      "  R²:    0.5835\n",
      "  WMAPE: 59.90%\n",
      "\n",
      "TEST:\n",
      "  R²:    0.6461\n",
      "  WMAPE: 48.23%\n",
      "\n",
      "⚠️  Posible overfitting detectado\n"
     ]
    }
   ],
   "source": [
    "# Evaluar todos los conjuntos\n",
    "all_metrics = evaluate_all_sets_manual(\n",
    "    predictor=predictor,\n",
    "    dm_norm=dm_norm,\n",
    "    train_tensor=train_tensor,\n",
    "    full_target=full_target,\n",
    "    train_length=len(train_tensor),\n",
    "    val_length=len(val_tensor)\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar overfitting\n",
    "train_val_diff = all_metrics['train']['r2'] - all_metrics['val']['r2']\n",
    "if train_val_diff > 0.10:\n",
    "    print(\"\\n⚠️  Posible overfitting detectado\")\n",
    "else:\n",
    "    print(\"\\n✅ Sin overfitting significativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0da61ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo TimeThenSpace guardado en models/TimeThenSpace_kyle_complete.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ========== 1. GUARDAR MODELO ENTRENADO ==========\n",
    "def save_model_complete(predictor, feature_cols, well_mapping, edge_index_tensor, edge_weight, model_name=\"TimeThenSpace\", save_dir=\"models\"):\n",
    "    \"\"\"Guardar modelo completo con metadatos\"\"\"\n",
    "    Path(save_dir).mkdir(exist_ok=True),\n",
    "    \n",
    "    # Guardar modelo completo\n",
    "    torch.save({\n",
    "        'model_state_dict': predictor.model.state_dict(),\n",
    "        'model_class': type(predictor.model).__name__,\n",
    "        'input_size': 8,\n",
    "        'output_size': 3,  \n",
    "        'n_nodes': 3,\n",
    "        'horizon': 7,\n",
    "        'feature_cols': feature_cols,\n",
    "        'well_mapping': well_mapping,\n",
    "        'edge_index': edge_index_tensor,  # ✅ Guardar grafo\n",
    "        'edge_weight': edge_weight, \n",
    "        'model_params': {\n",
    "            'hidden_size': 96,\n",
    "            'rnn_layers': 3,\n",
    "            'gnn_kernel': 5,\n",
    "            'dropout': 0.1,\n",
    "            'output_size':3\n",
    "        }\n",
    "    }, f\"{save_dir}/{model_name}_kyle_complete.pt\")\n",
    "    \n",
    "    print(f\"Modelo {model_name} guardado en {save_dir}/{model_name}_kyle_complete.pt\")\n",
    "\n",
    "\n",
    "save_model_complete(\n",
    "    predictor=predictor,\n",
    "    feature_cols=feature_cols,\n",
    "    well_mapping=well_mapping,\n",
    "    edge_index_tensor=edge_index_tensor,\n",
    "    edge_weight=edge_weight\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffff3df",
   "metadata": {},
   "source": [
    "## SPACETHENTIME MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from tsl.nn.blocks.encoders import RNN\n",
    "from tsl.nn.layers import NodeEmbedding, DiffConv\n",
    "from einops.layers.torch import Rearrange\n",
    "class SpaceThenTimeModel(nn.Module):\n",
    "    def __init__(self, input_size, n_nodes, horizon, edge_index, edge_weight, \n",
    "                 hidden_size=64, rnn_layers=1, gnn_kernel=3, dropout=0.1, output_size=3):\n",
    "        super(SpaceThenTimeModel, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size      # 8\n",
    "        self.output_size = output_size    # 3\n",
    "        self.horizon = horizon            # 7\n",
    "        self.n_nodes = n_nodes            # 4\n",
    "        \n",
    "        self.encoder = nn.Linear(input_size, hidden_size)\n",
    "        self.node_embeddings = NodeEmbedding(n_nodes, hidden_size)\n",
    "        \n",
    "        # Primero espacio, después tiempo\n",
    "        self.space_nn = DiffConv(\n",
    "            in_channels=hidden_size,\n",
    "            out_channels=hidden_size, \n",
    "            k=gnn_kernel\n",
    "        )\n",
    "        \n",
    "        self.time_nn = RNN(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            n_layers=rnn_layers,\n",
    "            cell='gru',\n",
    "            return_only_last_state=True\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Linear(hidden_size, output_size * horizon)\n",
    "        \n",
    "        self.rearrange = Rearrange('b n (t f) -> b t n f', t=horizon, f=output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.register_buffer('edge_index', edge_index)\n",
    "        self.register_buffer('edge_weight', edge_weight)\n",
    "    \n",
    "    def forward(self, x):\n",
    "    \n",
    "        # Encoder: [B, W, N, 8] → [B, W, N, hidden]\n",
    "        x_enc = self.encoder(x)\n",
    "        \n",
    "        # Add embeddings\n",
    "        x_emb = x_enc + self.node_embeddings()\n",
    "        \n",
    "        # Procesar espacialmente cada timestep\n",
    "        batch_size, seq_len, n_nodes, features = x_emb.shape\n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            # Spatial: [B, N, hidden] → [B, N, hidden]\n",
    "            h_t = self.space_nn(x_emb[:, t], self.edge_index, self.edge_weight)\n",
    "            outputs.append(h_t)\n",
    "        \n",
    "        # Stack: [B, W, N, hidden]\n",
    "        h_seq = torch.stack(outputs, dim=1)\n",
    "        \n",
    "        # Temporal: [B, W, N, hidden] → [B, N, hidden]\n",
    "        h = self.time_nn(h_seq)\n",
    "        \n",
    "        # Dropout\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        # Decoder: [B, N, hidden] → [B, N, horizon*output_size]\n",
    "        # Ejemplo: [B, 4, 96] → [B, 4, 21]\n",
    "        x_out = self.decoder(h)\n",
    "        \n",
    "        # Rearrange: [B, N, 21] → [B, 7, N, 3]\n",
    "        x_horizon = self.rearrange(x_out)\n",
    "        \n",
    "        return x_horizon\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfc8c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaceThenTimeModel(\n",
      "  (encoder): Linear(in_features=8, out_features=128, bias=True)\n",
      "  (node_embeddings): NodeEmbedding(n_nodes=3, embedding_size=128)\n",
      "  (space_nn): DiffConv(128, 128)\n",
      "  (time_nn): RNN(\n",
      "    (rnn): GRU(128, 128)\n",
      "  )\n",
      "  (decoder): Linear(in_features=128, out_features=21, bias=True)\n",
      "  (rearrange): Rearrange('b n (t f) -> b t n f', t=7, f=3)\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelSTT = SpaceThenTimeModel(\n",
    "    input_size=8,\n",
    "    output_size=3,\n",
    "    n_nodes=3,\n",
    "    horizon=7,\n",
    "    edge_index=edge_index_tensor,\n",
    "    edge_weight=edge_weight,\n",
    "    hidden_size=128,\n",
    "    rnn_layers=1,\n",
    "    gnn_kernel=2,\n",
    ")\n",
    "print(modelSTT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91882611",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "\n",
      "  | Name          | Type               | Params | Mode \n",
      "-------------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE          | 0      | train\n",
      "1 | train_metrics | MetricCollection   | 0      | train\n",
      "2 | val_metrics   | MetricCollection   | 0      | train\n",
      "3 | test_metrics  | MetricCollection   | 0      | train\n",
      "4 | model         | SpaceThenTimeModel | 185 K  | train\n",
      "-------------------------------------------------------------\n",
      "185 K     Trainable params\n",
      "0         Non-trainable params\n",
      "185 K     Total params\n",
      "0.741     Total estimated model params size (MB)\n",
      "24        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento STT para Kyle Field...\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['edge_index', 'edge_weight'] are filtered out. Only args ['x'] are forwarded to the model (SpaceThenTimeModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 125/125 [00:09<00:00, 12.63it/s, v_num=39, val_mae=0.276, val_mse=0.397, val_r2=0.647, train_mae=0.374, train_mse=0.415, train_r2=0.583]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved. New best score: 0.276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 125/125 [00:09<00:00, 12.62it/s, v_num=39, val_mae=0.261, val_mse=0.383, val_r2=0.658, train_mae=0.259, train_mse=0.311, train_r2=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.014 >= min_delta = 0.01. New best score: 0.261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 125/125 [00:11<00:00, 10.98it/s, v_num=39, val_mae=0.251, val_mse=0.391, val_r2=0.652, train_mae=0.236, train_mse=0.303, train_r2=0.695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.011 >= min_delta = 0.01. New best score: 0.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 125/125 [00:14<00:00,  8.86it/s, v_num=39, val_mae=0.256, val_mse=0.376, val_r2=0.664, train_mae=0.215, train_mse=0.290, train_r2=0.708]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mae did not improve in the last 15 records. Best score: 0.251. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 125/125 [00:14<00:00,  8.86it/s, v_num=39, val_mae=0.256, val_mse=0.376, val_r2=0.664, train_mae=0.215, train_mse=0.290, train_r2=0.708]\n",
      "Testing DataLoader 0: 100%|██████████| 42/42 [00:01<00:00, 26.87it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.10311809927225113\n",
      "        test_mae            0.10311811417341232\n",
      "        test_mse            0.07588354498147964\n",
      "         test_r2            0.9286361932754517\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Resultados finales SpaceThenTimeModel:\n",
      "test_mae: 0.1031\n",
      "test_mse: 0.0759\n",
      "test_r2: 0.9286\n",
      "test_loss: 0.1031\n"
     ]
    }
   ],
   "source": [
    "# Crear predictor con métricas\n",
    "predictorSTT = Predictor(\n",
    "    model=modelSTT,\n",
    "    optim_class=torch.optim.AdamW,\n",
    "    optim_kwargs={'lr': 0.0003, 'weight_decay': 0.005},\n",
    "    loss_fn=MaskedMAE(),\n",
    "    metrics={\n",
    "        'mae': MaskedMAE(),\n",
    "        'mse': MaskedMSE(),\n",
    "        'r2': MaskedR2()\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Checkpoint optimizado para Kyle Field\n",
    "checkpoint_callbackSTT = ModelCheckpoint(\n",
    "    dirpath='logs/kyle_field',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',             \n",
    "    mode='min',\n",
    "    filename='kyle-spacetime-{epoch:02d}-{val_mae:.4f}',\n",
    "    save_weights_only=True,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Early stopping para evitar overfitting\n",
    "early_stoppingSTT = EarlyStopping(\n",
    "    monitor='val_mae',              \n",
    "    patience=15,                  \n",
    "    min_delta=0.01,                 \n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Trainer optimizado para Kyle Field\n",
    "trainerSTT = pl.Trainer(\n",
    "    max_epochs=100,                 \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,        \n",
    "    limit_train_batches=None,       \n",
    "    val_check_interval=1.0,         \n",
    "    log_every_n_steps=5,            \n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callbackSTT, early_stoppingSTT],\n",
    "    deterministic=False,            \n",
    "    benchmark=True                  \n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento STT para Kyle Field...\")\n",
    "trainerSTT.fit(predictorSTT, datamodule=dm_norm)\n",
    "\n",
    "# Evaluación final\n",
    "test_resultsSTT = trainerSTT.test(predictorSTT, datamodule=dm_norm)\n",
    "print(\"\\nResultados finales SpaceThenTimeModel:\")\n",
    "for metric, value in test_resultsSTT[0].items():\n",
    "    if 'mape' not in metric.lower():  \n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14b662f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN COMPLETA: TRAIN, VAL y TEST\n",
      "================================================================================\n",
      "\n",
      "[0/5] Recreando scalers desde datos de train...\n",
      "  Scaler 0 (Oil (m3)): mean=4.0149, std=2.7042\n",
      "  Scaler 1 (Gas (m3)): mean=8.0968, std=5.4370\n",
      "  Scaler 2 (Produced Water (m3)): mean=1.2803, std=2.0721\n",
      "✓ Scalers recreados con datos de TRAIN\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO TODOS LOS CONJUNTOS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TRAIN\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TRAIN...\n",
      "✓ Predicciones: torch.Size([4000, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-2.28, 14.26]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 1562317.62]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TRAIN\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          18611.46 m³\n",
      "  RMSE:         65749.33 m³\n",
      "  R²:             0.7229\n",
      "  WMAPE:           41.29 %\n",
      "  SMAPE:           97.56 %\n",
      "  MAPE (>10):     104.81 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 138,445\n",
      "  MAE:         30730.90 m³\n",
      "  R²:            0.7195\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             75.30        26.95      0.7531    \n",
      "Gas (m3)             55741.84     41.32      0.6263    \n",
      "Produced Water (m3)  17.23        40.61      0.5686    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de VALIDATION...\n",
      "✓ Predicciones: torch.Size([1424, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-1.49, 12.38]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 237674.62]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           8633.55 m³\n",
      "  RMSE:         33355.35 m³\n",
      "  R²:             0.5272\n",
      "  WMAPE:           62.28 %\n",
      "  SMAPE:          136.74 %\n",
      "  MAPE (>10):     105.69 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,257\n",
      "  MAE:         20177.80 m³\n",
      "  R²:            0.5093\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             43.30        33.40      0.7929    \n",
      "Gas (m3)             25833.88     62.37      0.4363    \n",
      "Produced Water (m3)  23.48        55.02      0.6340    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TEST\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TEST...\n",
      "✓ Predicciones: torch.Size([1316, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.73, 12.32]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 223721.55]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TEST\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           8460.11 m³\n",
      "  RMSE:         31137.92 m³\n",
      "  R²:             0.6334\n",
      "  WMAPE:           49.71 %\n",
      "  SMAPE:          128.92 %\n",
      "  MAPE (>10):      47.17 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,117\n",
      "  MAE:         20894.29 m³\n",
      "  R²:            0.5650\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             21.97        21.22      0.9069    \n",
      "Gas (m3)             25348.39     49.78      0.5316    \n",
      "Produced Water (m3)  9.95         29.18      0.8191    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPARACIÓN: TRAIN vs VAL vs TEST\n",
      "================================================================================\n",
      "\n",
      "Métrica         TRAIN           VAL             TEST           \n",
      "-----------------------------------------------------------------\n",
      "R²              0.72            0.53            0.63           \n",
      "MAE (m³)        18611.46        8633.55         8460.11        \n",
      "WMAPE (%)       41.29           62.28           49.71          \n",
      "RMSE (m³)       65749.33        33355.35        31137.92       \n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE OVERFITTING\n",
      "================================================================================\n",
      "\n",
      "R² por conjunto:\n",
      "  Train: 0.7229\n",
      "  Val:   0.5272\n",
      "  Test:  0.6334\n",
      "\n",
      "⚠️  POSIBLE OVERFITTING:\n",
      "   Diferencia Train-Val: 0.1957 (>0.10)\n",
      "   El modelo se ajusta demasiado a los datos de entrenamiento\n",
      "\n",
      "⚠️  Diferencia Val-Test: 0.1062\n",
      "   Posible variabilidad en distribución de datos\n",
      "================================================================================\n",
      "\n",
      "⚠️  Posible overfitting detectado\n"
     ]
    }
   ],
   "source": [
    "# Evaluar todos los conjuntos\n",
    "all_metrics = evaluate_all_sets_manual(\n",
    "    predictor=predictorSTT,\n",
    "    dm_norm=dm_norm,\n",
    "    train_tensor=train_tensor,\n",
    "    full_target=full_target,\n",
    "    train_length=len(train_tensor),\n",
    "    val_length=len(val_tensor)\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar overfitting\n",
    "train_val_diff = all_metrics['train']['r2'] - all_metrics['val']['r2']\n",
    "if train_val_diff > 0.10:\n",
    "    print(\"\\n⚠️  Posible overfitting detectado\")\n",
    "else:\n",
    "    print(\"\\n✅ Sin overfitting significativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90b55972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SpaceThenTime guardado en models/SpaceThenTime_kyle_complete.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ========== 1. GUARDAR MODELO ENTRENADO ==========\n",
    "def save_model_complete(predictor, feature_cols, well_mapping, edge_index_tensor, edge_weight, model_name=\"SpaceThenTime\", save_dir=\"models\"):\n",
    "    \"\"\"Guardar modelo completo con metadatos\"\"\"\n",
    "    Path(save_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Guardar modelo completo\n",
    "    torch.save({\n",
    "        'model_state_dict': predictor.model.state_dict(),\n",
    "        'model_class': type(predictor.model).__name__,\n",
    "        'input_size': 8,\n",
    "        'output_size': 3,\n",
    "        'n_nodes': 3,\n",
    "        'horizon': 7,\n",
    "        'feature_cols': feature_cols,\n",
    "        'well_mapping': well_mapping,\n",
    "        'edge_index': edge_index_tensor,  # ✅ Guardar grafo\n",
    "        'edge_weight': edge_weight, \n",
    "        'model_params': {\n",
    "            'hidden_size': 128,\n",
    "            'rnn_layers': 1,\n",
    "            'gnn_kernel': 2,\n",
    "            'output_size':3\n",
    "        }\n",
    "    }, f\"{save_dir}/{model_name}_kyle_complete.pt\")\n",
    "    \n",
    "    print(f\"Modelo {model_name} guardado en {save_dir}/{model_name}_kyle_complete.pt\")\n",
    "\n",
    "# Guardar modelo actual\n",
    "save_model_complete(\n",
    "    predictor=predictorSTT,\n",
    "    feature_cols=feature_cols,\n",
    "    well_mapping=well_mapping,\n",
    "    edge_index_tensor=edge_index_tensor,\n",
    "    edge_weight=edge_weight\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eefe73a",
   "metadata": {},
   "source": [
    "## CRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bcbead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tsl.nn.models import DCRNNModel\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "class SimpleDCRNNModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 edge_index, edge_weight,\n",
    "                 hidden_size: int = 128,\n",
    "                 rnn_layers: int = 3,\n",
    "                 dropout: float = 0.1,\n",
    "                 output_size: int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size      # 8\n",
    "        self.output_size = output_size    # 3\n",
    "        self.horizon = horizon            # 7\n",
    "        self.n_nodes = n_nodes            # 4\n",
    "        \n",
    "        self.dcrnn = DCRNNModel(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=input_size,  \n",
    "            horizon=horizon,\n",
    "            n_layers=rnn_layers\n",
    "        )\n",
    "        \n",
    "  \n",
    "        self.projection = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        # Registrar topología del grafo\n",
    "        self.register_buffer('edge_index', edge_index)\n",
    "        self.register_buffer('edge_weight', edge_weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "      \n",
    "        # DCRNN: [B, 14, 4, 8] → [B, 7, 4, 8]\n",
    "        out = self.dcrnn(x, edge_index=self.edge_index, edge_weight=self.edge_weight)\n",
    "        \n",
    "        # Proyección: [B, 7, 4, 8] → [B, 7, 4, 3]\n",
    "        out = self.projection(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0bf3701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleDCRNNModel(\n",
      "  (dcrnn): DCRNNModel(\n",
      "    (input_encoder): Linear(in_features=8, out_features=128, bias=True)\n",
      "    (dcrnn): DCRNN(cell=DCRNNCell, return_only_last_state=True)\n",
      "    (readout): MLPDecoder(\n",
      "      (readout): MLP(\n",
      "        (mlp): Sequential(\n",
      "          (0): Dense(\n",
      "            (affinity): Linear(in_features=128, out_features=256, bias=True)\n",
      "            (activation): ReLU()\n",
      "            (dropout): Identity()\n",
      "          )\n",
      "        )\n",
      "        (readout): Linear(in_features=256, out_features=56, bias=True)\n",
      "      )\n",
      "      (rearrange): Rearrange('b n (h f) -> b h n f', f=8, h=7)\n",
      "    )\n",
      "  )\n",
      "  (projection): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Instanciar modelo\n",
    "\n",
    "modelDCRNN = SimpleDCRNNModel(\n",
    "    input_size=8,\n",
    "    output_size=3,\n",
    "    n_nodes=3,\n",
    "    horizon=7,\n",
    "    edge_index=edge_index_tensor,\n",
    "    edge_weight=edge_weight,\n",
    "    hidden_size=128,\n",
    "    rnn_layers=3,\n",
    "    dropout=0.1\n",
    ")\n",
    "print(modelDCRNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a4c1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE        | 0      | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | SimpleDCRNNModel | 1.5 M  | train\n",
      "-----------------------------------------------------------\n",
      "1.5 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 M     Total params\n",
      "6.097     Total estimated model params size (MB)\n",
      "58        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento DCRNN para Kyle Field...\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['edge_index', 'edge_weight'] are filtered out. Only args ['x'] are forwarded to the model (SimpleDCRNNModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 125/125 [01:17<00:00,  1.60it/s, v_num=40, val_mae=0.294, val_mse=0.446, val_r2=0.606, train_mae=0.463, train_mse=0.653, train_r2=0.343]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved. New best score: 0.294\n",
      "Epoch 0, global step 125: 'val_mae' reached 0.29447 (best 0.29447), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-DCRNN-epoch=00-val_mae=0.2945.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 125/125 [01:22<00:00,  1.51it/s, v_num=40, val_mae=0.276, val_mse=0.424, val_r2=0.625, train_mae=0.242, train_mse=0.338, train_r2=0.660]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.018 >= min_delta = 0.01. New best score: 0.276\n",
      "Epoch 1, global step 250: 'val_mae' reached 0.27614 (best 0.27614), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-DCRNN-epoch=01-val_mae=0.2761.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [01:29<00:00,  1.39it/s, v_num=40, val_mae=0.260, val_mse=0.410, val_r2=0.635, train_mae=0.221, train_mse=0.321, train_r2=0.677]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.016 >= min_delta = 0.01. New best score: 0.260\n",
      "Epoch 2, global step 375: 'val_mae' reached 0.26007 (best 0.26007), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-DCRNN-epoch=02-val_mae=0.2601.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 125/125 [01:31<00:00,  1.37it/s, v_num=40, val_mae=0.256, val_mse=0.407, val_r2=0.638, train_mae=0.213, train_mse=0.314, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 500: 'val_mae' reached 0.25645 (best 0.25645), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-DCRNN-epoch=03-val_mae=0.2564.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 125/125 [01:34<00:00,  1.33it/s, v_num=40, val_mae=0.259, val_mse=0.411, val_r2=0.635, train_mae=0.208, train_mse=0.309, train_r2=0.689]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 125/125 [01:18<00:00,  1.58it/s, v_num=40, val_mae=0.252, val_mse=0.407, val_r2=0.638, train_mae=0.203, train_mse=0.304, train_r2=0.695]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 750: 'val_mae' reached 0.25239 (best 0.25239), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-DCRNN-epoch=05-val_mae=0.2524.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 125/125 [01:16<00:00,  1.63it/s, v_num=40, val_mae=0.266, val_mse=0.429, val_r2=0.621, train_mae=0.201, train_mse=0.301, train_r2=0.697]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 875: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 125/125 [01:15<00:00,  1.65it/s, v_num=40, val_mae=0.269, val_mse=0.429, val_r2=0.620, train_mae=0.197, train_mse=0.295, train_r2=0.704]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1000: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 125/125 [01:15<00:00,  1.65it/s, v_num=40, val_mae=0.253, val_mse=0.407, val_r2=0.637, train_mae=0.196, train_mse=0.294, train_r2=0.703]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 125/125 [03:17<00:00,  0.63it/s, v_num=40, val_mae=0.255, val_mse=0.409, val_r2=0.636, train_mae=0.194, train_mse=0.292, train_r2=0.706]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 1250: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 125/125 [02:23<00:00,  0.87it/s, v_num=40, val_mae=0.259, val_mse=0.414, val_r2=0.633, train_mae=0.191, train_mse=0.289, train_r2=0.710]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1375: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 125/125 [01:15<00:00,  1.66it/s, v_num=40, val_mae=0.262, val_mse=0.421, val_r2=0.626, train_mae=0.190, train_mse=0.288, train_r2=0.711]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1500: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 125/125 [01:18<00:00,  1.60it/s, v_num=40, val_mae=0.259, val_mse=0.414, val_r2=0.632, train_mae=0.188, train_mse=0.283, train_r2=0.715]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 125/125 [01:14<00:00,  1.67it/s, v_num=40, val_mae=0.255, val_mse=0.412, val_r2=0.633, train_mae=0.185, train_mse=0.282, train_r2=0.717]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1750: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 125/125 [01:15<00:00,  1.66it/s, v_num=40, val_mae=0.257, val_mse=0.413, val_r2=0.633, train_mae=0.185, train_mse=0.281, train_r2=0.717]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1875: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 125/125 [01:33<00:00,  1.34it/s, v_num=40, val_mae=0.257, val_mse=0.410, val_r2=0.635, train_mae=0.182, train_mse=0.278, train_r2=0.719]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 2000: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 125/125 [03:20<00:00,  0.62it/s, v_num=40, val_mae=0.255, val_mse=0.406, val_r2=0.638, train_mae=0.182, train_mse=0.277, train_r2=0.722]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 125/125 [04:50<00:00,  0.43it/s, v_num=40, val_mae=0.261, val_mse=0.418, val_r2=0.628, train_mae=0.179, train_mse=0.272, train_r2=0.726]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mae did not improve in the last 15 records. Best score: 0.260. Signaling Trainer to stop.\n",
      "Epoch 17, global step 2250: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 125/125 [04:50<00:00,  0.43it/s, v_num=40, val_mae=0.261, val_mse=0.418, val_r2=0.628, train_mae=0.179, train_mse=0.272, train_r2=0.726]\n",
      "Testing DataLoader 0: 100%|██████████| 42/42 [00:10<00:00,  4.20it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.1135929748415947\n",
      "        test_mae            0.1135929748415947\n",
      "        test_mse            0.09930799901485443\n",
      "         test_r2            0.9038656949996948\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Resultados finales TimeThenSpace:\n",
      "test_mae: 0.1136\n",
      "test_mse: 0.0993\n",
      "test_r2: 0.9039\n",
      "test_loss: 0.1136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear predictor con métricas\n",
    "predictorDCRNN = Predictor(\n",
    "    model=modelDCRNN,\n",
    "    optim_class=torch.optim.AdamW,\n",
    "    optim_kwargs={'lr': 0.0003, 'weight_decay': 0.0019},\n",
    "    loss_fn=MaskedMAE(),\n",
    "    metrics={\n",
    "        'mae': MaskedMAE(),\n",
    "        'mse': MaskedMSE(),\n",
    "        'r2': MaskedR2()\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Checkpoint optimizado para Kyle Field\n",
    "checkpoint_callbackDCRNN = ModelCheckpoint(\n",
    "    dirpath='logs/kyle_field',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',            \n",
    "    mode='min',\n",
    "    filename='kyle-DCRNN-{epoch:02d}-{val_mae:.4f}',\n",
    "    save_weights_only=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Early stopping para evitar overfitting\n",
    "early_stoppingDCRNN = EarlyStopping(\n",
    "    monitor='val_mae',            \n",
    "    patience=15,                   \n",
    "    min_delta=0.01,                \n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Trainer optimizado para Kyle Field\n",
    "trainerDCRNN = pl.Trainer(\n",
    "    max_epochs=100,                 \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,          \n",
    "    limit_train_batches=None,       \n",
    "    val_check_interval=1.0,         \n",
    "    log_every_n_steps=5,           \n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callbackDCRNN, early_stoppingDCRNN],\n",
    "    deterministic=False,            \n",
    "    benchmark=True                  \n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento DCRNN para Kyle Field...\")\n",
    "trainerDCRNN.fit(predictorDCRNN, datamodule=dm_norm)\n",
    "\n",
    "# Evaluación final\n",
    "test_resultsDCRNN = trainerDCRNN.test(predictorDCRNN, datamodule=dm_norm)\n",
    "print(\"\\nResultados finales TimeThenSpace:\")\n",
    "for metric, value in test_resultsDCRNN[0].items():\n",
    "    if 'mape' not in metric.lower(): \n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d480e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN COMPLETA: TRAIN, VAL y TEST\n",
      "================================================================================\n",
      "\n",
      "[0/5] Recreando scalers desde datos de train...\n",
      "  Scaler 0 (Oil (m3)): mean=4.0149, std=2.7042\n",
      "  Scaler 1 (Gas (m3)): mean=8.0968, std=5.4370\n",
      "  Scaler 2 (Produced Water (m3)): mean=1.2803, std=2.0721\n",
      "✓ Scalers recreados con datos de TRAIN\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO TODOS LOS CONJUNTOS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TRAIN\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TRAIN...\n",
      "✓ Predicciones: torch.Size([4000, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.27, 13.81]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 994842.69]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TRAIN\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          16171.31 m³\n",
      "  RMSE:         62145.93 m³\n",
      "  R²:             0.7520\n",
      "  WMAPE:           35.89 %\n",
      "  SMAPE:           82.77 %\n",
      "  MAPE (>10):     116.25 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 138,490\n",
      "  MAE:         26066.39 m³\n",
      "  R²:            0.7584\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             70.85        25.37      0.7546    \n",
      "Gas (m3)             48426.66     35.91      0.6655    \n",
      "Produced Water (m3)  16.43        38.70      0.5895    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de VALIDATION...\n",
      "✓ Predicciones: torch.Size([1424, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.22, 13.35]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 627022.12]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          12262.28 m³\n",
      "  RMSE:         46446.54 m³\n",
      "  R²:             0.0833\n",
      "  WMAPE:           88.45 %\n",
      "  SMAPE:          125.31 %\n",
      "  MAPE (>10):     307.68 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,257\n",
      "  MAE:         28027.20 m³\n",
      "  R²:            0.0984\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             47.16        36.38      0.7561    \n",
      "Gas (m3)             36716.49     88.65      -0.0930   \n",
      "Produced Water (m3)  23.19        54.36      0.6476    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TEST\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TEST...\n",
      "✓ Predicciones: torch.Size([1316, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.25, 13.33]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 617837.56]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TEST\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          11026.52 m³\n",
      "  RMSE:         40839.82 m³\n",
      "  R²:             0.3694\n",
      "  WMAPE:           64.79 %\n",
      "  SMAPE:          120.65 %\n",
      "  MAPE (>10):      84.87 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,117\n",
      "  MAE:         27240.22 m³\n",
      "  R²:            0.2546\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             35.79        34.57      0.7742    \n",
      "Gas (m3)             33027.09     64.86      0.1943    \n",
      "Produced Water (m3)  16.66        48.86      0.6543    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPARACIÓN: TRAIN vs VAL vs TEST\n",
      "================================================================================\n",
      "\n",
      "Métrica         TRAIN           VAL             TEST           \n",
      "-----------------------------------------------------------------\n",
      "R²              0.75            0.08            0.37           \n",
      "MAE (m³)        16171.31        12262.28        11026.52       \n",
      "WMAPE (%)       35.89           88.45           64.79          \n",
      "RMSE (m³)       62145.93        46446.54        40839.82       \n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE OVERFITTING\n",
      "================================================================================\n",
      "\n",
      "R² por conjunto:\n",
      "  Train: 0.7520\n",
      "  Val:   0.0833\n",
      "  Test:  0.3694\n",
      "\n",
      "⚠️  POSIBLE OVERFITTING:\n",
      "   Diferencia Train-Val: 0.6688 (>0.10)\n",
      "   El modelo se ajusta demasiado a los datos de entrenamiento\n",
      "\n",
      "⚠️  Diferencia Val-Test: 0.2861\n",
      "   Posible variabilidad en distribución de datos\n",
      "================================================================================\n",
      "\n",
      "⚠️  Posible overfitting detectado\n"
     ]
    }
   ],
   "source": [
    "# Evaluar todos los conjuntos\n",
    "all_metrics = evaluate_all_sets_manual(\n",
    "    predictor=predictorDCRNN,\n",
    "    dm_norm=dm_norm,\n",
    "    train_tensor=train_tensor,\n",
    "    full_target=full_target,\n",
    "    train_length=len(train_tensor),\n",
    "    val_length=len(val_tensor)\n",
    ")\n",
    "\n",
    "\n",
    "# Verificar overfitting\n",
    "train_val_diff = all_metrics['train']['r2'] - all_metrics['val']['r2']\n",
    "if train_val_diff > 0.10:\n",
    "    print(\"\\n⚠️  Posible overfitting detectado\")\n",
    "else:\n",
    "    print(\"\\n✅ Sin overfitting significativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "72a0c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SimpleDCRNNModel guardado en models/SimpleDCRNNModel_kyle_complete.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ========== 1. GUARDAR MODELO ENTRENADO ==========\n",
    "def save_model_complete(predictor,  feature_cols, well_mapping, edge_index_tensor, edge_weight,model_name=\"SimpleDCRNNModel\", save_dir=\"models\"):\n",
    "    \"\"\"Guardar modelo completo con metadatos\"\"\"\n",
    "    Path(save_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Guardar modelo completo\n",
    "    torch.save({\n",
    "        'model_state_dict': predictor.model.state_dict(),\n",
    "        'model_class': type(predictor.model).__name__,\n",
    "        'input_size': 8,\n",
    "        'n_nodes': 3,\n",
    "        'horizon': 7,\n",
    "        'feature_cols': feature_cols,\n",
    "        'well_mapping': well_mapping,\n",
    "        'edge_index': edge_index_tensor,  # ✅ Guardar grafo\n",
    "        'edge_weight': edge_weight, \n",
    "        'model_params': {\n",
    "            'hidden_size': 128,\n",
    "            'rnn_layers': 3,\n",
    "            'dropout': 0.1,\n",
    "            'output_size':3\n",
    "        }\n",
    "    }, f\"{save_dir}/{model_name}_kyle_complete.pt\")\n",
    "    \n",
    "    print(f\"Modelo {model_name} guardado en {save_dir}/{model_name}_kyle_complete.pt\")\n",
    "\n",
    "\n",
    "\n",
    "save_model_complete(\n",
    "    predictor=predictorDCRNN,\n",
    "    feature_cols=feature_cols,\n",
    "    well_mapping=well_mapping,\n",
    "    edge_index_tensor=edge_index_tensor,\n",
    "    edge_weight=edge_weight\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a6f273",
   "metadata": {},
   "source": [
    "## GatedGraphNetworkModel (libreria TSL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "331beb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tsl.nn.models import GatedGraphNetworkModel\n",
    "\n",
    "class GatedGraphModel(nn.Module):\n",
    "    def __init__(self, input_size: int, n_nodes: int, horizon: int,\n",
    "                 edge_index, edge_weight,\n",
    "                 hidden_size: int = 128,\n",
    "                 input_window_size: int = 14,\n",
    "                 enc_layers: int = 1,\n",
    "                 gnn_layers: int = 3,\n",
    "                 output_size: int = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.horizon = horizon\n",
    "        self.n_nodes = n_nodes\n",
    "        \n",
    "        self.gated_gnn = GatedGraphNetworkModel(\n",
    "            input_size=input_size,\n",
    "            input_window_size=dm_norm.window,\n",
    "            horizon=horizon,\n",
    "            n_nodes=n_nodes,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=input_size,\n",
    "            exog_size=0,\n",
    "            enc_layers=enc_layers,\n",
    "            gnn_layers=gnn_layers,\n",
    "            full_graph=True,\n",
    "            activation='silu'\n",
    "        )\n",
    "        \n",
    "        self.projection = nn.Linear(input_size, output_size)\n",
    "        \n",
    "        # Convertir edge_index: (tensor, tensor) -> tensor [2, num_edges]\n",
    "        if isinstance(edge_index, tuple) and len(edge_index) == 2:\n",
    "            edge_index = torch.stack(edge_index, dim=0)\n",
    "        elif not isinstance(edge_index, torch.Tensor):\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "        else:\n",
    "            edge_index = edge_index.long()\n",
    "        \n",
    "        # Convertir edge_weight\n",
    "        if not isinstance(edge_weight, torch.Tensor):\n",
    "            edge_weight = torch.tensor(edge_weight, dtype=torch.float32)\n",
    "        else:\n",
    "            edge_weight = edge_weight.float()\n",
    "        \n",
    "        self.register_buffer('edge_index', edge_index)\n",
    "        self.register_buffer('edge_weight', edge_weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.gated_gnn(x, edge_index=self.edge_index)\n",
    "        out = self.projection(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e215ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GatedGraphModel(\n",
      "  (gated_gnn): GatedGraphNetworkModel(\n",
      "    (input_encoder): Sequential(\n",
      "      (0): Linear(in_features=112, out_features=128, bias=True)\n",
      "    )\n",
      "    (encoder_layers): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (1): SiLU()\n",
      "        (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (emb): NodeEmbedding(n_nodes=3, embedding_size=128)\n",
      "    (gcn_layers): ModuleList(\n",
      "      (0-2): 3 x GatedGraphNetwork(128, 128)\n",
      "    )\n",
      "    (decoder): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "      (1): SiLU()\n",
      "    )\n",
      "    (readout): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=56, bias=True)\n",
      "      (1): Rearrange('b n (h f) -> b h n f', h=7, f=8)\n",
      "    )\n",
      "  )\n",
      "  (projection): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_window_size = 14  \n",
    "\n",
    "modelggcm = GatedGraphModel(\n",
    "    input_size=8,\n",
    "    output_size=3,\n",
    "    n_nodes=3,\n",
    "    horizon=7,\n",
    "    edge_index=edge_index,\n",
    "    edge_weight=edge_weight,\n",
    "    hidden_size=128,\n",
    "    input_window_size=dm_norm.window, \n",
    "    enc_layers=1,  # 1 (mapear rnn_layers a enc_layers)\n",
    "    gnn_layers=3,   # 2 (mapear gnn_kernel a gnn_layers)\n",
    ")\n",
    "print(modelggcm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae5f80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "\n",
      "  | Name          | Type             | Params | Mode \n",
      "-----------------------------------------------------------\n",
      "0 | loss_fn       | MaskedMAE        | 0      | train\n",
      "1 | train_metrics | MetricCollection | 0      | train\n",
      "2 | val_metrics   | MetricCollection | 0      | train\n",
      "3 | test_metrics  | MetricCollection | 0      | train\n",
      "4 | model         | GatedGraphModel  | 294 K  | train\n",
      "-----------------------------------------------------------\n",
      "294 K     Trainable params\n",
      "0         Non-trainable params\n",
      "294 K     Total params\n",
      "1.178     Total estimated model params size (MB)\n",
      "76        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento GATEDGRAPH para Kyle Field...\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Arguments ['edge_index', 'edge_weight'] are filtered out. Only args ['x'] are forwarded to the model (GatedGraphModel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 125/125 [00:03<00:00, 32.20it/s, v_num=41, val_mae=0.326, val_mse=0.404, val_r2=0.641, train_mae=0.305, train_mse=0.351, train_r2=0.647]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved. New best score: 0.326\n",
      "Epoch 0, global step 125: 'val_mae' reached 0.32597 (best 0.32597), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=00-val_mae=0.3260.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 125/125 [00:03<00:00, 33.14it/s, v_num=41, val_mae=0.297, val_mse=0.411, val_r2=0.635, train_mae=0.264, train_mse=0.320, train_r2=0.677]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.029 >= min_delta = 0.01. New best score: 0.297\n",
      "Epoch 1, global step 250: 'val_mae' reached 0.29673 (best 0.29673), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=01-val_mae=0.2967.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 125/125 [00:04<00:00, 25.06it/s, v_num=41, val_mae=0.284, val_mse=0.412, val_r2=0.634, train_mae=0.254, train_mse=0.317, train_r2=0.681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.012 >= min_delta = 0.01. New best score: 0.284\n",
      "Epoch 2, global step 375: 'val_mae' reached 0.28442 (best 0.28442), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=02-val_mae=0.2844.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 125/125 [00:05<00:00, 21.06it/s, v_num=41, val_mae=0.294, val_mse=0.418, val_r2=0.628, train_mae=0.250, train_mse=0.317, train_r2=0.681]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 500: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 125/125 [00:06<00:00, 20.45it/s, v_num=41, val_mae=0.281, val_mse=0.397, val_r2=0.647, train_mae=0.247, train_mse=0.315, train_r2=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 625: 'val_mae' reached 0.28056 (best 0.28056), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=04-val_mae=0.2806.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 125/125 [00:08<00:00, 15.44it/s, v_num=41, val_mae=0.278, val_mse=0.397, val_r2=0.648, train_mae=0.243, train_mse=0.314, train_r2=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 750: 'val_mae' reached 0.27780 (best 0.27780), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=05-val_mae=0.2778.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 125/125 [00:08<00:00, 15.44it/s, v_num=41, val_mae=0.297, val_mse=0.424, val_r2=0.623, train_mae=0.241, train_mse=0.316, train_r2=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 875: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 125/125 [00:06<00:00, 18.75it/s, v_num=41, val_mae=0.287, val_mse=0.383, val_r2=0.659, train_mae=0.239, train_mse=0.313, train_r2=0.684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1000: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 125/125 [00:07<00:00, 16.51it/s, v_num=41, val_mae=0.280, val_mse=0.411, val_r2=0.635, train_mae=0.239, train_mse=0.314, train_r2=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 1125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 125/125 [00:07<00:00, 16.32it/s, v_num=41, val_mae=0.263, val_mse=0.395, val_r2=0.649, train_mae=0.238, train_mse=0.314, train_r2=0.684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_mae improved by 0.021 >= min_delta = 0.01. New best score: 0.263\n",
      "Epoch 9, global step 1250: 'val_mae' reached 0.26344 (best 0.26344), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=09-val_mae=0.2634.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 125/125 [00:08<00:00, 13.98it/s, v_num=41, val_mae=0.273, val_mse=0.405, val_r2=0.640, train_mae=0.235, train_mse=0.312, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 1375: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 125/125 [00:09<00:00, 13.04it/s, v_num=41, val_mae=0.272, val_mse=0.390, val_r2=0.653, train_mae=0.235, train_mse=0.314, train_r2=0.684]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 1500: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 125/125 [00:10<00:00, 11.86it/s, v_num=41, val_mae=0.274, val_mse=0.385, val_r2=0.658, train_mae=0.233, train_mse=0.313, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 1625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 125/125 [00:10<00:00, 11.50it/s, v_num=41, val_mae=0.271, val_mse=0.401, val_r2=0.644, train_mae=0.231, train_mse=0.314, train_r2=0.683]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 1750: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 125/125 [00:10<00:00, 12.33it/s, v_num=41, val_mae=0.282, val_mse=0.392, val_r2=0.651, train_mae=0.234, train_mse=0.311, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 1875: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 125/125 [00:08<00:00, 14.09it/s, v_num=41, val_mae=0.280, val_mse=0.405, val_r2=0.641, train_mae=0.233, train_mse=0.312, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 2000: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 125/125 [00:08<00:00, 14.22it/s, v_num=41, val_mae=0.268, val_mse=0.390, val_r2=0.653, train_mae=0.231, train_mse=0.312, train_r2=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 2125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 125/125 [00:07<00:00, 16.67it/s, v_num=41, val_mae=0.267, val_mse=0.401, val_r2=0.643, train_mae=0.231, train_mse=0.311, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 2250: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 125/125 [00:06<00:00, 20.10it/s, v_num=41, val_mae=0.269, val_mse=0.394, val_r2=0.650, train_mae=0.231, train_mse=0.313, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 2375: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 125/125 [00:05<00:00, 24.74it/s, v_num=41, val_mae=0.270, val_mse=0.406, val_r2=0.639, train_mae=0.229, train_mse=0.312, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 2500: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 125/125 [00:04<00:00, 27.21it/s, v_num=41, val_mae=0.270, val_mse=0.398, val_r2=0.646, train_mae=0.228, train_mse=0.312, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 2625: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 125/125 [00:04<00:00, 28.04it/s, v_num=41, val_mae=0.267, val_mse=0.393, val_r2=0.650, train_mae=0.231, train_mse=0.312, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 2750: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 125/125 [00:04<00:00, 30.00it/s, v_num=41, val_mae=0.262, val_mse=0.400, val_r2=0.645, train_mae=0.228, train_mse=0.311, train_r2=0.687]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 2875: 'val_mae' reached 0.26243 (best 0.26243), saving model to 'C:\\\\Users\\\\DIEGO\\\\OneDrive\\\\Escritorio\\\\Maestria Ciencia de datos\\\\Tesis\\\\Tests\\\\mape copy\\\\logs\\\\kyle_field\\\\kyle-ggcn-epoch=22-val_mae=0.2624.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 125/125 [00:04<00:00, 29.80it/s, v_num=41, val_mae=0.270, val_mse=0.400, val_r2=0.645, train_mae=0.228, train_mse=0.313, train_r2=0.685]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 3000: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 125/125 [00:04<00:00, 30.25it/s, v_num=41, val_mae=0.268, val_mse=0.401, val_r2=0.643, train_mae=0.227, train_mse=0.312, train_r2=0.686]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_mae did not improve in the last 15 records. Best score: 0.263. Signaling Trainer to stop.\n",
      "Epoch 24, global step 3125: 'val_mae' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 125/125 [00:04<00:00, 30.19it/s, v_num=41, val_mae=0.268, val_mse=0.401, val_r2=0.643, train_mae=0.227, train_mse=0.312, train_r2=0.686]\n",
      "Testing DataLoader 0: 100%|██████████| 42/42 [00:00<00:00, 79.17it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_loss           0.09131509065628052\n",
      "        test_mae            0.09131508320569992\n",
      "        test_mse            0.07423687726259232\n",
      "         test_r2            0.9302377104759216\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Resultados finales GGCM:\n",
      "test_mae: 0.0913\n",
      "test_mse: 0.0742\n",
      "test_r2: 0.9302\n",
      "test_loss: 0.0913\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "predictorggcm = Predictor(\n",
    "    model=modelggcm,                 \n",
    "    optim_class=torch.optim.Adam,  \n",
    "    optim_kwargs={\n",
    "        'lr': 0.005,                        \n",
    "        'weight_decay': 0.01,               \n",
    "        'betas': (0.9, 0.999),              \n",
    "        'eps': 1e-8\n",
    "    },    \n",
    "    loss_fn=MaskedMAE(),               \n",
    "    metrics={\n",
    "        'mae': MaskedMAE(),\n",
    "        'mse': MaskedMSE(),\n",
    "        'r2': MaskedR2()\n",
    "    }              \n",
    ")\n",
    "\n",
    "checkpoint_callbackggcm = ModelCheckpoint(\n",
    "    dirpath='logs/kyle_field',\n",
    "    save_top_k=1,\n",
    "    monitor='val_mae',         \n",
    "    mode='min',\n",
    "    filename='kyle-ggcn-{epoch:02d}-{val_mae:.4f}',\n",
    "    save_weights_only=False,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Early stopping para evitar overfitting\n",
    "early_stoppingggcm = EarlyStopping(\n",
    "    monitor='val_mae',              \n",
    "    patience=15,                   \n",
    "    min_delta=0.01,                \n",
    "    mode='min',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Trainer optimizado para Kyle Field\n",
    "trainerggcm = pl.Trainer(\n",
    "    max_epochs=100,                \n",
    "    accelerator='gpu' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=1,\n",
    "    gradient_clip_val=1.0,        \n",
    "    limit_train_batches=None,       \n",
    "    val_check_interval=1.0,         \n",
    "    log_every_n_steps=5,            \n",
    "    enable_progress_bar=True,\n",
    "    callbacks=[checkpoint_callbackggcm, early_stoppingggcm],\n",
    "    deterministic=False,            \n",
    "    benchmark=True                  \n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "print(\"Iniciando entrenamiento GATEDGRAPH para Kyle Field...\")\n",
    "trainerggcm.fit(predictorggcm, datamodule=dm_norm)\n",
    "\n",
    "# Evaluación final\n",
    "test_resultsggcm = trainerggcm.test(predictorggcm, datamodule=dm_norm)\n",
    "print(\"\\nResultados finales GGCM:\")\n",
    "for metric, value in test_resultsggcm[0].items():\n",
    "    if 'mape' not in metric.lower(): \n",
    "        print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81582447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EVALUACIÓN COMPLETA: TRAIN, VAL y TEST\n",
      "================================================================================\n",
      "\n",
      "[0/5] Recreando scalers desde datos de train...\n",
      "  Scaler 0 (Oil (m3)): mean=4.0149, std=2.7042\n",
      "  Scaler 1 (Gas (m3)): mean=8.0968, std=5.4370\n",
      "  Scaler 2 (Produced Water (m3)): mean=1.2803, std=2.0721\n",
      "✓ Scalers recreados con datos de TRAIN\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO TODOS LOS CONJUNTOS\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TRAIN\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TRAIN...\n",
      "✓ Predicciones: torch.Size([4000, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-3.52, 14.20]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 1468402.12]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TRAIN\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:          22472.57 m³\n",
      "  RMSE:         78350.50 m³\n",
      "  R²:             0.6061\n",
      "  WMAPE:           49.91 %\n",
      "  SMAPE:           65.64 %\n",
      "  MAPE (>10):     114.61 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 138,419\n",
      "  MAE:         37484.33 m³\n",
      "  R²:            0.5895\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             86.80        31.08      0.6958    \n",
      "Gas (m3)             67310.79     49.95      0.4689    \n",
      "Produced Water (m3)  20.12        47.50      0.4658    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de VALIDATION...\n",
      "✓ Predicciones: torch.Size([1424, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.94, 12.76]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 346671.22]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: VALIDATION\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           8238.81 m³\n",
      "  RMSE:         30519.21 m³\n",
      "  R²:             0.6042\n",
      "  WMAPE:           59.43 %\n",
      "  SMAPE:           84.39 %\n",
      "  MAPE (>10):     155.71 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,257\n",
      "  MAE:         17764.97 m³\n",
      "  R²:            0.6554\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             44.87        34.62      0.7594    \n",
      "Gas (m3)             24646.67     59.51      0.5281    \n",
      "Produced Water (m3)  24.89        58.34      0.5403    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "EVALUANDO: TEST\n",
      "================================================================================\n",
      "\n",
      "[1/4] Obteniendo predicciones de TEST...\n",
      "✓ Predicciones: torch.Size([1316, 7, 3, 3])\n",
      "  Nota: Están en escala NORMALIZADA\n",
      "\n",
      "[2/4] Desnormalizando...\n",
      "✓ Desnormalizado (aún con log): [-0.56, 12.53]\n",
      "\n",
      "[3/4] Invirtiendo log-transform (np.expm1)...\n",
      "✓ Escala original (m³): [0.00, 275281.66]\n",
      "\n",
      "[4/4] Calculando métricas...\n",
      "\n",
      "================================================================================\n",
      "MÉTRICAS: TEST\n",
      "================================================================================\n",
      "\n",
      "📊 MÉTRICAS GLOBALES:\n",
      "  MAE:           6593.78 m³\n",
      "  RMSE:         24500.51 m³\n",
      "  R²:             0.7730\n",
      "  WMAPE:           38.74 %\n",
      "  SMAPE:           57.07 %\n",
      "  MAPE (>10):      54.75 %\n",
      "\n",
      "📊 PRODUCCIÓN ACTIVA (> 10 m³):\n",
      "  Registros: 33,117\n",
      "  MAE:         16105.37 m³\n",
      "  R²:            0.7364\n",
      "\n",
      "📊 MÉTRICAS POR VARIABLE:\n",
      "Variable             MAE (m³)     WMAPE (%)  R²        \n",
      "------------------------------------------------------------\n",
      "Oil (m3)             17.86        17.25      0.9104    \n",
      "Gas (m3)             19753.12     38.79      0.7100    \n",
      "Produced Water (m3)  10.36        30.37      0.7854    \n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "COMPARACIÓN: TRAIN vs VAL vs TEST\n",
      "================================================================================\n",
      "\n",
      "Métrica         TRAIN           VAL             TEST           \n",
      "-----------------------------------------------------------------\n",
      "R²              0.61            0.60            0.77           \n",
      "MAE (m³)        22472.57        8238.81         6593.78        \n",
      "WMAPE (%)       49.91           59.43           38.74          \n",
      "RMSE (m³)       78350.50        30519.21        24500.51       \n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS DE OVERFITTING\n",
      "================================================================================\n",
      "\n",
      "R² por conjunto:\n",
      "  Train: 0.6061\n",
      "  Val:   0.6042\n",
      "  Test:  0.7730\n",
      "\n",
      "✅ BUEN BALANCE:\n",
      "   Diferencia Train-Val: 0.0019 (<0.05)\n",
      "   El modelo generaliza bien\n",
      "\n",
      "⚠️  Diferencia Val-Test: 0.1688\n",
      "   Posible variabilidad en distribución de datos\n",
      "================================================================================\n",
      "\n",
      "📊 RESUMEN GATED GRAPH NETWORK:\n",
      "\n",
      "TRAIN:\n",
      "  R²:    0.6061\n",
      "  WMAPE: 49.91%\n",
      "\n",
      "VAL:\n",
      "  R²:    0.6042\n",
      "  WMAPE: 59.43%\n",
      "\n",
      "TEST:\n",
      "  R²:    0.7730\n",
      "  WMAPE: 38.74%\n",
      "\n",
      "✅ Sin overfitting significativo\n"
     ]
    }
   ],
   "source": [
    "# Evaluar todos los conjuntos\n",
    "all_metrics = evaluate_all_sets_manual(\n",
    "    predictor=predictorggcm,\n",
    "    dm_norm=dm_norm,\n",
    "    train_tensor=train_tensor,\n",
    "    full_target=full_target,\n",
    "    train_length=len(train_tensor),\n",
    "    val_length=len(val_tensor)\n",
    ")\n",
    "\n",
    "# Acceder a métricas individuales\n",
    "print(\"\\n📊 RESUMEN GATED GRAPH NETWORK:\")\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(f\"  R²:    {all_metrics['train']['r2']:.4f}\")\n",
    "print(f\"  WMAPE: {all_metrics['train']['wmape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nVAL:\")\n",
    "print(f\"  R²:    {all_metrics['val']['r2']:.4f}\")\n",
    "print(f\"  WMAPE: {all_metrics['val']['wmape']:.2f}%\")\n",
    "\n",
    "print(f\"\\nTEST:\")\n",
    "print(f\"  R²:    {all_metrics['test']['r2']:.4f}\")\n",
    "print(f\"  WMAPE: {all_metrics['test']['wmape']:.2f}%\")\n",
    "\n",
    "# Verificar overfitting\n",
    "train_val_diff = all_metrics['train']['r2'] - all_metrics['val']['r2']\n",
    "if train_val_diff > 0.10:\n",
    "    print(\"\\n⚠️  Posible overfitting detectado\")\n",
    "else:\n",
    "    print(\"\\n✅ Sin overfitting significativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6727a50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo GatedGraphModel guardado en models/GatedGraphModel_kyle_complete.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ========== 1. GUARDAR MODELO ENTRENADO ==========\n",
    "def save_model_complete(predictor,  feature_cols, well_mapping, edge_index_tensor, edge_weight,model_name=\"GatedGraphModel\", save_dir=\"models\"):\n",
    "    \"\"\"Guardar modelo completo con metadatos\"\"\"\n",
    "    Path(save_dir).mkdir(exist_ok=True)\n",
    "    \n",
    "    # Guardar modelo completo\n",
    "    torch.save({\n",
    "        'model_state_dict': predictor.model.state_dict(),\n",
    "        'model_class': type(predictor.model).__name__,\n",
    "        'input_size': 8,\n",
    "        'n_nodes': 3,\n",
    "        'horizon': 7,\n",
    "        'feature_cols': feature_cols,\n",
    "        'well_mapping': well_mapping,\n",
    "        'edge_index': edge_index_tensor,  # ✅ Guardar grafo\n",
    "        'edge_weight': edge_weight, \n",
    "        'model_params': {\n",
    "            'input_size':8,\n",
    "            'input_window_size': 14,\n",
    "            'n_nodes':3,\n",
    "            'horizon':7,\n",
    "            'edge_index': edge_index,\n",
    "            'edge_weight': edge_weight,\n",
    "            'hidden_size':128,\n",
    "            'enc_layers':1,  # 1 (mapear rnn_layers a enc_layers)\n",
    "            'gnn_layers':3,   # 2 (mapear gnn_kernel a gnn_layers)\n",
    "            'output_size' : 3\n",
    "        }\n",
    "    }, f\"{save_dir}/{model_name}_kyle_complete.pt\")\n",
    "    \n",
    "    print(f\"Modelo {model_name} guardado en {save_dir}/{model_name}_kyle_complete.pt\")\n",
    "\n",
    "# Guardar modelo actual\n",
    "save_model_complete(\n",
    "    predictor=predictorggcm,\n",
    "    feature_cols=feature_cols,\n",
    "    well_mapping=well_mapping,\n",
    "    edge_index_tensor=edge_index_tensor,\n",
    "    edge_weight=edge_weight\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
